{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "uber_fiber.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MLsT5sg_sgrC",
        "vss2OSb1sgrF",
        "FUTMtR2-sgrN",
        "OBWrWTrisgrY",
        "QUzUG2yqsgrp",
        "jKDiPHtJsgrr"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjeetSingh02/Notebooks/blob/master/uber_fiber.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dj18BaXsgrB",
        "colab_type": "text"
      },
      "source": [
        "**What is Fiber?**\n",
        "\n",
        "Fiber is a Python distributed computing library for modern computer clusters.\n",
        "\n",
        "**Note**: Fiber is experimental and the APIs are not stable. (Source: Github of Fiber)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLsT5sg_sgrC",
        "colab_type": "text"
      },
      "source": [
        "# Basic Properties"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC4Qb6kfsgrE",
        "colab_type": "text"
      },
      "source": [
        "* **Easy to use**\n",
        "    * Fiber allows you to write programs that run on a computer cluster level without the need to dive into the details of computer cluster.\n",
        "\n",
        "\n",
        "* **Easy to learn**\n",
        "    * Fiber provides the same API as Python's standard multiprocessing library that you are familiar with. If you know how to use multiprocessing, you can program a computer cluster with Fiber.\n",
        "\n",
        "\n",
        "* **Fast**\n",
        "    * Fiber's communication backbone is built on top of Nanomsg which is a high-performance asynchronous messaging library to allow fast and reliable communication.\n",
        "\n",
        "\n",
        "* **Batteries included**\n",
        "    * You don't need to deploy Fiber on computer clusters. You run it as the same way as running a normal application on a computer cluster and Fiber handles the rest for you.\n",
        "\n",
        "\n",
        "* **Reliable**\n",
        "    * Fiber has built-in error handling when you are running a pool of workers. Users can focus on writing the actual application code instead of dealing with crashed workers.\n",
        "\n",
        "\n",
        "* **Dynamic scaling**\n",
        "    * Fiber can dynamically allocate resources from computer clusters including CPU/Memory/GPU etc. It can scale up and down according to the computation needed by the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vss2OSb1sgrF",
        "colab_type": "text"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GmjaoAUsnr7",
        "colab_type": "text"
      },
      "source": [
        "Since fiber is just like any other python library, **pip install** will work as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGWGXFhRsgrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install fiber"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUTMtR2-sgrN",
        "colab_type": "text"
      },
      "source": [
        "# How to use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p-uBOAfsgrO",
        "colab_type": "text"
      },
      "source": [
        "To understand Fiber we will take one example. In this example, we will create a simple program that estimates Pi with [Monte Carlo Method](https://en.wikipedia.org/wiki/Monte_Carlo_method).<br>\n",
        "\n",
        "We will create a file **pi_estimation.py** with following content:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWmpilJqsgrP",
        "colab_type": "text"
      },
      "source": [
        " ```python\n",
        "from fiber import Pool\n",
        "import random\n",
        "\n",
        "NUM_SAMPLES = int(1e6)\n",
        "\n",
        "def is_inside(p):\n",
        "    x, y = random.random(), random.random()\n",
        "    return x * x + y * y < 1\n",
        "\n",
        "def main():\n",
        "    pool = Pool(processes=4)\n",
        "    pi = 4.0 * sum(pool.map(is_inside, range(0, NUM_SAMPLES))) / NUM_SAMPLES\n",
        "    print(\"Pi is roughly {}\".format(pi))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "    \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQbcC9N9sgrQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "998e370f-8d5a-4a1b-aea1-8d95f0abaecc"
      },
      "source": [
        "# After running this command we will get the estimated value of pi\n",
        "! python pi_estimation.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pi is roughly 3.139944\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0gvMWOvsgrX",
        "colab_type": "text"
      },
      "source": [
        "In this example, Fiber created a pool of 4 workers, passed all the workload to them and collected results from them. We can increase the degree of parallelism by increasing the number of Pool workers.\n",
        "\n",
        "Since this code ran on my local, it is essentially multiprocessing (different workers running on different cores) and not cluster computing.\n",
        "\n",
        "We will see cluster computing in next section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBWrWTrisgrY",
        "colab_type": "text"
      },
      "source": [
        "# Running on a Kubernetes cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CNXmr3usgrZ",
        "colab_type": "text"
      },
      "source": [
        "To run our program on a computer cluster, we need to containarize it. Following **Dockerfile** and **docker build** command will do that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubJcx7zPsgra",
        "colab_type": "text"
      },
      "source": [
        "Dockerfile:\n",
        "\n",
        "```python    \n",
        "FROM python:3.6-buster\n",
        "ADD pi_estimation.py /root/pi_estimation.py\n",
        "RUN pip install fiber\n",
        "```\n",
        "\n",
        "Docker Build command : \n",
        "```python    \n",
        "docker build -t fiber-pi-estimation .\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzcWrCHZsgrb",
        "colab_type": "text"
      },
      "source": [
        "Now we can run the same code with **docker backend**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4YG3kkysgrc",
        "colab_type": "code",
        "colab": {},
        "outputId": "bcdce1a4-870d-475c-a71a-9f5ef63315ce"
      },
      "source": [
        "! FIBER_BACKEND=docker FIBER_IMAGE=fiber-pi-estimation:latest python pi_estimation.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pi is roughly 3.142896\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZKCbv7nsgrh",
        "colab_type": "text"
      },
      "source": [
        "Some points to note:\n",
        "\n",
        "* **FIBER_BACKEND** tells Fiber what backend to use. Currently, Fiber supports these backends: *local*, *docker* and *kubernetes*. When FIBER_BACKEND is set to docker, all new processes will be launched through docker backend which means all of them will be running inside their own docker container.\n",
        "\n",
        "* **FIBER_IMAGE** tells Fiber what docker image to use when launching new containers. This container provides the running environment for your child processes, so it needs to have Fiber installed in it. And we already did that in the previous step when building the docker container.\n",
        "\n",
        "* **Note** that in this example, the master process (the one you started with python pi_estimation.py) still runs on local machine instead of inside a docker container. All the processes started by Fiber are inside containers.\n",
        "\n",
        "* Also, **note** that Fiber is not installed on all the system but it is there in docker containers as part of environment and thus all the systems have Fiber the other way around."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz2fOSLfsgri",
        "colab_type": "code",
        "colab": {},
        "outputId": "17dafefa-0548-49b9-d464-832640ce03ce"
      },
      "source": [
        "# You can check the containers launched by Fiber by running this command:\n",
        "!docker ps -a|grep fiber-pi-estimation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d41ef4ad7ee6        fiber-pi-estimation:latest   \"/usr/local/bin/pyth…\"   25 seconds ago      Exited (1) 14 seconds ago                       PoolWorker-4-bb15d42e-3c0d-474e-9f48-ccf466fd0522\r\n",
            "db4a5b510d56        fiber-pi-estimation:latest   \"/usr/local/bin/pyth…\"   25 seconds ago      Exited (1) 14 seconds ago                       PoolWorker-3-eaef3af5-a862-4251-b1e6-c77e29e304b6\r\n",
            "46c0a175b6a1        fiber-pi-estimation:latest   \"/usr/local/bin/pyth…\"   25 seconds ago      Exited (1) 14 seconds ago                       PoolWorker-2-96ae84be-7ef4-4a99-94b7-9cfbaa8fae99\r\n",
            "2822b7583f3d        fiber-pi-estimation:latest   \"/usr/local/bin/pyth…\"   25 seconds ago      Exited (1) 14 seconds ago                       PoolWorker-1-35e610ca-13a5-433d-9edc-02328d3ddbe5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8048sC2sgrn",
        "colab_type": "text"
      },
      "source": [
        "*As you can see in the above cell there are four containers started by fiber for the computation. Since currently we are running in local these containers will be running on different cores of my system and not on different computers. But in essence, same thing will happen in case of cluster computing. Here 4 containers are running on different cores, there 4 containers will be running on different computers.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVbiLqGPsgro",
        "colab_type": "text"
      },
      "source": [
        "To run on Kubernetes cluster we have to install **kubectl**, **Google Cloud SDK** and need to authenticate docker to access **Google Container Registry (GCR)**. After that these 4 commands will do the trick.\n",
        "\n",
        "**Note**: I have not tested below 4 commands as I dont have access to a compute cluster or GCP credit. So I am copying the codes from the Fiber repo.\n",
        "\n",
        "```Python\n",
        "# tag our image and push it to a container registry that is accessible by Kubernetes cluster.\n",
        "docker tag fiber-pi-estimation:latest gcr.io/[your-project-name]/fiber-pi-estimation:latest\n",
        "docker push gcr.io/[your-project-name]/fiber-pi-estimation:latest\n",
        "\n",
        "# launch job     \n",
        "kubectl create job fiber-pi-estimation --image=gcr.io/[your-project-name]/fiber-pi-estimation:latest -- python3 /root/pi_estimation.py\n",
        "    \n",
        "# The job has been submitted to Kubernetes cluster, and now we can get its\n",
        "# logs. It may take some time before the job is scheduled. We will get our\n",
        "# output after running this command\n",
        "kubectl logs $(kubectl get po|grep fiber-pi-estimation|awk '{print $1}')\n",
        "```\n",
        "\n",
        "On Kubernetes, Fiber behaves similarly to when running locally with Docker. **Each process becomes a Kubernetes pod and all the pods work collectively to compute our estimation of Pi**!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CQy1kbav4Ti",
        "colab_type": "text"
      },
      "source": [
        "To avoid the hassle, we can also use **fiber**, which is a command line tool that can be used to avoid all the above things, but currently that works with GCP only.\n",
        "\n",
        "Below command will work as an alternative to all the above steps. We will be using the same Dockerfile:\n",
        "\n",
        "```Python\n",
        "fiber run -a python3 /root/pi_estimation.py\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUzUG2yqsgrp",
        "colab_type": "text"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGmNuRVgsgrq",
        "colab_type": "text"
      },
      "source": [
        "* Fiber can be used to run your code on a cluster.\n",
        "\n",
        "* What fiber does is that it takes your code in a docker container (or any other container) and with Kubernetes (or some other orchestrator) runs this code inside container on multiple machines. With containers, all the code and enironment will be consistent.\n",
        "\n",
        "* You need not install Fiber on all the machines. You just have to install it on on the master machine, rest will be handeled by Fiber.\n",
        "\n",
        "* Fiber works similar to Multiprocessing in Python. In multiprocessing you run your code on different cores of the same machine. Whereas in Fiber the code is running on different machines.\n",
        "\n",
        "* Fiber automatically handles the workers which get crashed and replaces with available new worker and restarts the task, if still pending, on new worker.\n",
        "\n",
        "* Fiber is fast owing to the fact that Fiber's communication backbone is built on top of Nanomsg (A high-performance asynchronous messaging library), \n",
        "\n",
        "* With Fiber we can scale out with ease."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKDiPHtJsgrr",
        "colab_type": "text"
      },
      "source": [
        "# Side Note"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfUMQcOisgrr",
        "colab_type": "text"
      },
      "source": [
        "**Kubernetes-vs-Fiber**\n",
        "\n",
        "Note: I am not sure about Kubernetes part as I don't know much about Kubernetes.\n",
        "\n",
        "We can achieve cluster computing using Kubernetes only but with Kubernetes whole code runs on different workers. whereas with fiber code runs on different workers but we can get the output of all the workers back to the master node to assemble. "
      ]
    }
  ]
}
