{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ONNX.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNszzlO8IGELCiXZ7CUtWrW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ec744822c7a4d22a1eaa5b81af0311f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eba8bff7fff14e94930e8bb4c7ba4e0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_353aeb482fc94a738e918291b30a7971",
              "IPY_MODEL_209a5ee8542a44c4b17c4c9674cafbcd"
            ]
          }
        },
        "eba8bff7fff14e94930e8bb4c7ba4e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "353aeb482fc94a738e918291b30a7971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c4be611bbc69424f9e819e49283b999c",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4966400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4966400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f09ff1945c34446584db79ffe9b6e52b"
          }
        },
        "209a5ee8542a44c4b17c4c9674cafbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68b46cf7fd6e45edb51917910b0f8b6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4.74M/4.74M [08:09&lt;00:00, 10.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_102e95fc05b34f45a7d2aa82387eda6b"
          }
        },
        "c4be611bbc69424f9e819e49283b999c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f09ff1945c34446584db79ffe9b6e52b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68b46cf7fd6e45edb51917910b0f8b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "102e95fc05b34f45a7d2aa82387eda6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjeetSingh02/Notebooks/blob/master/ONNX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbbZuvfxWagH"
      },
      "source": [
        "! pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTHVI6msvOzS"
      },
      "source": [
        "! pip install -U tf2onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2EGA6NovYSh"
      },
      "source": [
        "! python -m tf2onnx.convert --saved-model \"/content/modelDir/model/1602656296\" --output model.onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXwGA3eYwWZZ"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiA3VnV0wYGv"
      },
      "source": [
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgKVp0spwYr_"
      },
      "source": [
        "LABEL = \"survived\"\n",
        "feature_columns = []\n",
        "NUMERIC_COLUMNS = ['age', 'fare']\n",
        "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', \n",
        "                       'embark_town', 'alone']\n",
        "\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = dftrain[feature_name].unique()\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXYFCQ7bwaW3"
      },
      "source": [
        "def make_train_input_fn(df, num_epochs):\n",
        "    return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x = df,\n",
        "    y = df[LABEL],\n",
        "    batch_size = 128,\n",
        "    num_epochs = num_epochs,\n",
        "    shuffle = True,\n",
        "    queue_capacity = 1000\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltUozeSxwb8y"
      },
      "source": [
        "def make_prediction_input_fn(df):\n",
        "  return tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
        "    x = df,\n",
        "    y = None,\n",
        "    batch_size = 128,\n",
        "    shuffle = False,\n",
        "    queue_capacity = 1000\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lst_sSf7wdQJ"
      },
      "source": [
        "# Instantiate the pre-made estimator\n",
        "model = tf.estimator.LinearClassifier(feature_columns)\n",
        "\n",
        "# Train the model\n",
        "model.train(make_train_input_fn(dftrain, num_epochs=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo84Mroswf8n"
      },
      "source": [
        "predDicts = list(model.predict(make_prediction_input_fn(dfeval)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsB4qjhiwhc4",
        "outputId": "b4123115-28b3-4fc8-f62e-f32617b0c172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds = []\n",
        "for pred in predDicts[:10]:\n",
        "    preds.append(np.argmax(pred[\"probabilities\"]))\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1, 1, 0, 1, 1, 0, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhQkfqBewixZ",
        "outputId": "2d82f4d8-7f60-4830-8b76-2117c1ebec1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "inputFn = \\\n",
        "tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
        "    tf.feature_column.make_parse_example_spec(feature_columns)\n",
        ")\n",
        "\n",
        "OUTDIR = 'modelDir'\n",
        "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
        "\n",
        "modelBasePath = os.path.join(OUTDIR, \"model\")\n",
        "modelPath = model.export_saved_model(modelBasePath, inputFn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:145: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpytjlp56q/model.ckpt-49\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: modelDir/model/temp-1602656296/saved_model.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPLKhWyJwlJw"
      },
      "source": [
        "# Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCcuM5Ln3dDB"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyhmLxc83gRC",
        "outputId": "d6b1d582-f0ae-4ae4-b432-57c9e4b527e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "URL = 'https://storage.googleapis.com/applied-dl/heart.csv'\n",
        "df = pd.read_csv(URL)\n",
        "df.pop(\"thal\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>160</td>\n",
              "      <td>286</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>108</td>\n",
              "      <td>1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>120</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  ...  exang  oldpeak  slope  ca  target\n",
              "0   63    1   1       145   233  ...      0      2.3      3   0       0\n",
              "1   67    1   4       160   286  ...      1      1.5      2   3       1\n",
              "2   67    1   4       120   229  ...      1      2.6      2   2       0\n",
              "3   37    1   3       130   250  ...      0      3.5      3   0       0\n",
              "4   41    0   2       130   204  ...      0      1.4      1   0       0\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhmAj1j03i2j"
      },
      "source": [
        "train = df.sample(frac=0.8, random_state=2).reset_index()\n",
        "test = df.drop(train.index).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SeuEIR03qZM"
      },
      "source": [
        "yTrain = train.pop(\"target\")\n",
        "yTest = test.pop(\"target\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeyG8Kyo3seT"
      },
      "source": [
        "trainStats = train.describe().transpose()\n",
        "\n",
        "def normalize(x):\n",
        "    return (x - trainStats[\"mean\"]) / trainStats[\"std\"]\n",
        "\n",
        "xTrain = normalize(train)\n",
        "xTest = normalize(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wY_3Zss3vsE"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "     layers.Dense(units=128, activation=\"relu\", name=\"layer1\"),\n",
        "     layers.Dense(units=128, activation=\"relu\", name=\"layer2\"),\n",
        "     layers.Dense(units=1, name=\"outputLayer\")\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFBys0LL39MP"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp6goRMr4ABN",
        "outputId": "b46bfbbd-2866-40b2-f579-695a2e985ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "source": [
        "history = model.fit(\n",
        "    x=xTrain,\n",
        "    y=yTrain,\n",
        "    validation_data=(xTest, yTest),\n",
        "    epochs=5\n",
        ")   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Layer layer1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9162 - accuracy: 0.7975 - val_loss: 0.8683 - val_accuracy: 0.8525\n",
            "Epoch 2/5\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7375 - accuracy: 0.8554 - val_loss: 1.0329 - val_accuracy: 0.7869\n",
            "Epoch 3/5\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.8719 - val_loss: 0.7693 - val_accuracy: 0.8689\n",
            "Epoch 4/5\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8760 - val_loss: 0.5710 - val_accuracy: 0.8852\n",
            "Epoch 5/5\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.8884 - val_loss: 0.4900 - val_accuracy: 0.8689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llI8yikb4Bal",
        "outputId": "d7d234aa-e390-4e23-f474-4dcddb8c09d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "res = pd.DataFrame(history.history)\n",
        "res[\"epochs\"] = history.epoch\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epochs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.916225</td>\n",
              "      <td>0.797521</td>\n",
              "      <td>0.868335</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.737518</td>\n",
              "      <td>0.855372</td>\n",
              "      <td>1.032906</td>\n",
              "      <td>0.786885</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.551038</td>\n",
              "      <td>0.871901</td>\n",
              "      <td>0.769302</td>\n",
              "      <td>0.868852</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.402040</td>\n",
              "      <td>0.876033</td>\n",
              "      <td>0.570993</td>\n",
              "      <td>0.885246</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.335513</td>\n",
              "      <td>0.888430</td>\n",
              "      <td>0.490023</td>\n",
              "      <td>0.868852</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy  epochs\n",
              "0  0.916225  0.797521  0.868335      0.852459       0\n",
              "1  0.737518  0.855372  1.032906      0.786885       1\n",
              "2  0.551038  0.871901  0.769302      0.868852       2\n",
              "3  0.402040  0.876033  0.570993      0.885246       3\n",
              "4  0.335513  0.888430  0.490023      0.868852       4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL4r8xC939PL",
        "outputId": "75307445-5e4b-4816-b656-75c4e54640c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "loss, accuracy = model.evaluate(xTest, yTest, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 - 0s - loss: 0.4900 - accuracy: 0.8689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVKL9epW4EE3"
      },
      "source": [
        "preds = model.predict(xTest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXsrWzpG4EJ4"
      },
      "source": [
        "model.save(\"binaryClassification.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTbH6La54EMT"
      },
      "source": [
        "loadedModel = keras.models.load_model(\"/content/binaryClassification.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULsxm-7Q4aGf",
        "outputId": "1336bab2-13ca-4352-d5a9-c2c429b8abfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "loadedModel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "layer1 (Dense)               (None, 128)               1792      \n",
            "_________________________________________________________________\n",
            "layer2 (Dense)               (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "outputLayer (Dense)          (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 18,433\n",
            "Trainable params: 18,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH6m5s9T4bh6",
        "outputId": "55542767-055f-48b8-feb2-06acac72c6f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "(loadedModel.predict(xTest) > 0.5).astype(\"int32\").flatten()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1dRLxNh2SO0",
        "outputId": "aa4e7692-7a70-4b69-fb9d-12649ef30d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "! pip install keras2onnx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras2onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2f/c7aef8f8215c62d55ea05f5b36737c1726e4fea6c73970909523ae497fd9/keras2onnx-1.7.0-py3-none-any.whl (96kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102kB 4.0MB/s \n",
            "\u001b[?25hCollecting onnxconverter-common>=1.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/7a/7e30c643cd7d2ad87689188ef34ce93e657bd14da3605f87bcdbc19cd5b1/onnxconverter_common-1.7.0-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (2.23.0)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (1.7.0)\n",
            "Collecting fire\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras2onnx) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras2onnx) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from onnx->keras2onnx) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->keras2onnx) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire->keras2onnx) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->keras2onnx) (50.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=0b925a775864e4e9105239e5e7e34d252c39e51afe1a4f4c02d4f16a0ecda6f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "Successfully built fire\n",
            "Installing collected packages: onnxconverter-common, fire, keras2onnx\n",
            "Successfully installed fire-0.3.1 keras2onnx-1.7.0 onnxconverter-common-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQnZbDxM2Mjz"
      },
      "source": [
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.models import load_model\n",
        "import onnx\n",
        "import keras2onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiyQQUJh3LV2"
      },
      "source": [
        "model = load_model('/content/binaryClassification.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Wrqs6S2sl3",
        "outputId": "c22b207e-cf9c-454d-f2c2-d59738fd7571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "onnx_model_name = 'binaryClassification.onnx'\n",
        "onnx_model = keras2onnx.convert_keras(model, model.name)\n",
        "onnx.save_model(onnx_model, onnx_model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf executing eager_mode: True\n",
            "tf.keras model eager_mode: False\n",
            "The ONNX operator number change on the optimization: 13 -> 8\n",
            "The maximum opset needed by this model is only 9.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40KZGmHSooV7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGgvNUHxoofW",
        "outputId": "631e0d3f-d1bc-42cd-9209-aa91b10965a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "! pip install --upgrade onnx2keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting onnx2keras\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/68/647c88eb96546ebef79bf66ea633efca3e8cda866951a5e1003229880b36/onnx2keras-0.0.23.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: tensorflow in /usr/local/lib/python3.6/dist-packages (from onnx2keras) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from onnx2keras) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: onnx in /usr/local/lib/python3.6/dist-packages (from onnx2keras) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->onnx2keras) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx->onnx2keras) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow->onnx2keras) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->onnx2keras) (3.2.0)\n",
            "Building wheels for collected packages: onnx2keras\n",
            "  Building wheel for onnx2keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnx2keras: filename=onnx2keras-0.0.23-cp36-none-any.whl size=24159 sha256=fdefc89a37142d57d2bf792dfb084b695e7f15853b5eb1800415360c958b5198\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/d1/5a/644cd9e957d01977c2e7c5bcb75d8172ba0eab831e2471128d\n",
            "Successfully built onnx2keras\n",
            "Installing collected packages: onnx2keras\n",
            "Successfully installed onnx2keras-0.0.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XpqijFPo4t1"
      },
      "source": [
        "import onnx2keras\n",
        "from onnx2keras import onnx_to_keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhVGztbjorYJ",
        "outputId": "f319fdb3-1446-4062-e31a-836e3a00b725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        }
      },
      "source": [
        "onnx_model = onnx.load('/content/binaryClassification.onnx')\n",
        "k_model = onnx_to_keras(onnx_model, ['input_1'], name_policy='renumerate')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:onnx2keras:Converter is called.\n",
            "DEBUG:onnx2keras:List input shapes:\n",
            "DEBUG:onnx2keras:None\n",
            "DEBUG:onnx2keras:List inputs:\n",
            "DEBUG:onnx2keras:Input 0 -> layer1_input.\n",
            "DEBUG:onnx2keras:List outputs:\n",
            "DEBUG:onnx2keras:Output 0 -> outputLayer.\n",
            "DEBUG:onnx2keras:Gathering weights to dictionary.\n",
            "DEBUG:onnx2keras:Found weight outputLayer/kernel:0 with shape (128, 1).\n",
            "DEBUG:onnx2keras:Found weight outputLayer/bias:0 with shape (1,).\n",
            "DEBUG:onnx2keras:Found weight layer2/kernel:0 with shape (128, 128).\n",
            "DEBUG:onnx2keras:Found weight layer2/bias:0 with shape (128,).\n",
            "DEBUG:onnx2keras:Found weight layer1/kernel:0 with shape (13, 128).\n",
            "DEBUG:onnx2keras:Found weight layer1/bias:0 with shape (128,).\n",
            "DEBUG:onnx2keras:######\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Converting ONNX operation\n",
            "DEBUG:onnx2keras:type: MatMul\n",
            "DEBUG:onnx2keras:node_name: layer10\n",
            "DEBUG:onnx2keras:node_params: {'change_ordering': False, 'name_policy': 'renumerate'}\n",
            "DEBUG:onnx2keras:...\n",
            "DEBUG:onnx2keras:Check if all inputs are available:\n",
            "DEBUG:onnx2keras:Check input 0 (name layer1_input).\n",
            "DEBUG:onnx2keras:The input not found in layers / model inputs.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-f6f87fb3f5cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/binaryClassification.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mk_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx_to_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'input_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'renumerate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onnx2keras/converter.py\u001b[0m in \u001b[0;36monnx_to_keras\u001b[0;34m(onnx_model, input_names, input_shapes, name_policy, verbose, change_ordering)\u001b[0m\n\u001b[1;32m    168\u001b[0m                     \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_input\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current node is not in weights / model inputs / layers.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'... found all, continue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Current node is not in weights / model inputs / layers."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duO5p0kyorg_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT3fa6eDorpk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVhegOMBoryG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4RJzYNfiLQg",
        "outputId": "b809c42f-db7e-4c72-d8de-21f781c2c52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import caffe2.python.onnx.backend"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.6/lib2to3/PatternGrammar.txt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CalqXafYeCr3",
        "outputId": "621d5983-cbe5-4509-95c8-2ac158778c5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "model = onnx.load(\"/content/binaryClassification.onnx\")\n",
        "\n",
        "# prepare the caffe2 backend for executing the model this converts the ONNX model into a \n",
        "# Caffe2 NetDef that can execute it. Other ONNX backends, like one for CNTK will be \n",
        "# availiable soon.\n",
        "prepared_backend = caffe2.python.onnx.backend.prepare(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-baa878653c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Caffe2 NetDef that can execute it. Other ONNX backends, like one for CNTK will be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# availiable soon.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprepared_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaffe2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/caffe2/python/onnx/backend.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(cls, model, device, raw_values_dict, **kwargs)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mopset_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_inference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onnx/shape_inference.py\u001b[0m in \u001b[0;36minfer_shapes\u001b[0;34m(model, check_type)\u001b[0m\n\u001b[1;32m     33\u001b[0m                          'incorrect type: {}'.format(type(model)))\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0minferred_model_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minferred_model_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Inferred elem type differs from existing elem type: (DOUBLE) vs (FLOAT)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWxgsmpmij9F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPIp6XS3ikGe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFZnLoEmikny"
      },
      "source": [
        "! pip install onnx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNknOZlfikxT"
      },
      "source": [
        "# Some standard imports\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.onnx\n",
        "\n",
        "import onnx\n",
        "import caffe2.python.onnx.backend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJKOUn-aila8",
        "outputId": "10e3901d-e0f1-4a97-c86b-2bae512c8b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# Super Resolution model definition in PyTorch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "class SuperResolutionNet(nn.Module):\n",
        "    def __init__(self, upscale_factor, inplace=False):\n",
        "        super(SuperResolutionNet, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=inplace)\n",
        "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pixel_shuffle(self.conv4(x))\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal(self.conv3.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal(self.conv4.weight)\n",
        "\n",
        "# Create the super-resolution model by using the above model definition.\n",
        "torch_model = SuperResolutionNet(upscale_factor=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdppswPmiqes"
      },
      "source": [
        "# Load pretrained model weights\n",
        "model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\n",
        "batch_size = 1    # just a random number\n",
        "\n",
        "# Initialize model with the pretrained weights\n",
        "torch_model.load_state_dict(model_zoo.load_url(model_url))\n",
        "\n",
        "# set the train mode to false since we will only run the forward pass.\n",
        "torch_model.train(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLntcL3CiuD2"
      },
      "source": [
        "# Input to the model\n",
        "x = Variable(torch.randn(batch_size, 1, 224, 224), requires_grad=True)\n",
        "\n",
        "# Export the model\n",
        "torch_out = torch.onnx._export(torch_model,             # model being run \n",
        "                               x,                       # model input (or a tuple for multiple inputs) \n",
        "                               \"super_resolution.onnx\", # where to save the model (can be a file or file-like object)\n",
        "                               export_params=True)      # store the trained parameter weights inside the model file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doYOftQRjuRM"
      },
      "source": [
        "# Load the ONNX GraphProto object. Graph is a standard Python protobuf object\n",
        "model = onnx.load(\"/content/super_resolution.onnx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Wn7JLOjW_q",
        "outputId": "ff29939b-f335-42f5-8aed-0ad7a80b995c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "# prepare the caffe2 backend for executing the model this converts the ONNX model into a \n",
        "# Caffe2 NetDef that can execute it. Other ONNX backends, like one for CNTK will be \n",
        "# availiable soon.\n",
        "prepared_backend = caffe2.python.onnx.backend.prepare(model)\n",
        "\n",
        "# run the model in Caffe2\n",
        "\n",
        "# Construct a map from input names to Tensor data.\n",
        "# The graph of the model itself contains inputs for all weight parameters, after the input image.\n",
        "# Since the weights are already embedded, we just need to pass the input image.\n",
        "# Set the first input\n",
        "W = {model.graph.input[0].name: x.data.numpy()}\n",
        "\n",
        "# Run the Caffe2 net:\n",
        "c2_out = prepared_backend.run(W)[0]\n",
        "\n",
        "# Verify the numerical correctness upto 3 decimal places\n",
        "np.testing.assert_almost_equal(torch_out.data.cpu().numpy(), c2_out, decimal=3)\n",
        "\n",
        "print(\"Exported model has been executed on Caffe2 backend, and the result looks good!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-748ddaa1f658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Caffe2 NetDef that can execute it. Other ONNX backends, like one for CNTK will be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# availiable soon.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprepared_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaffe2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# run the model in Caffe2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/caffe2/python/onnx/backend.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(cls, model, device, raw_values_dict, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0mdevice_option\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0minit_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onnx_model_to_caffe2_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_values_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/caffe2/python/onnx/backend.py\u001b[0m in \u001b[0;36m_onnx_model_to_caffe2_net\u001b[0;34m(cls, onnx_model, device, opset_version, include_initializers)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mdevice_option\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolish_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0minit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0mpred_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onnx/utils.py\u001b[0m in \u001b[0;36mpolish_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_inference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onnx/optimizer.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, passes, fixed_point)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0moptimized_model_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_fixedpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moptimized_model_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimized_model_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Input 1 is undefined!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2R9MELhkAiO"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = ['SqueezeNet', 'squeezenet1_0', 'squeezenet1_1']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'squeezenet1_0': 'https://download.pytorch.org/models/squeezenet1_0-a815701f.pth',\n",
        "    'squeezenet1_1': 'https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)\n",
        "\n",
        "\n",
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=1000):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=False),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=False),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=False),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=False),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=False),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=False),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "\n",
        "\n",
        "def squeezenet1_1(pretrained=False, **kwargs):\n",
        "    r\"\"\"SqueezeNet 1.1 model from the `official SqueezeNet repo\n",
        "    <https://github.com/DeepScale/SqueezeNet/tree/master/SqueezeNet_v1.1>`_.\n",
        "    SqueezeNet 1.1 has 2.4x less computation and slightly fewer parameters\n",
        "    than SqueezeNet 1.0, without sacrificing accuracy.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = SqueezeNet(version=1.1, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['squeezenet1_1']))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3luxAgggkBLV",
        "outputId": "020341cd-1597-4ab1-ca37-796190d6607a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "9ec744822c7a4d22a1eaa5b81af0311f",
            "eba8bff7fff14e94930e8bb4c7ba4e0e",
            "353aeb482fc94a738e918291b30a7971",
            "209a5ee8542a44c4b17c4c9674cafbcd",
            "c4be611bbc69424f9e819e49283b999c",
            "f09ff1945c34446584db79ffe9b6e52b",
            "68b46cf7fd6e45edb51917910b0f8b6e",
            "102e95fc05b34f45a7d2aa82387eda6b"
          ]
        }
      },
      "source": [
        "# Get pretrained squeezenet model\n",
        "torch_model = squeezenet1_1(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:92: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth\" to /root/.cache/torch/hub/checkpoints/squeezenet1_1-f364aa15.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ec744822c7a4d22a1eaa5b81af0311f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4966400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5bRXJ3VkE-E",
        "outputId": "5660922a-b610-48ac-8f15-0d3fb0d9eb9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from torch.autograd import Variable\n",
        "batch_size = 1    # just a random number\n",
        "\n",
        "# Input to the model\n",
        "x = Variable(torch.randn(batch_size, 3, 224, 224), requires_grad=True)\n",
        "\n",
        "# Export the model\n",
        "torch_out = torch.onnx._export(torch_model,             # model being run\n",
        "                               x,                       # model input (or a tuple for multiple inputs)\n",
        "                               \"squeezenet.onnx\",       # where to save the model (can be a file or file-like object)\n",
        "                               export_params=True)      # store the trained parameter weights inside the model file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/onnx/utils.py:44: UserWarning: You are exporting the model to ONNX while in training mode with 'train' parameter not specified. The model will default to inference mode export. If you wish to export a training amenable ONNX model, specify training=TrainingMode.TRAINING or training=TrainingMode.PRESERVE (to preserve the original model state) in torch.onnx.export().\n",
            "  warnings.warn(\"You are exporting the model to ONNX while in training mode with \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDWPG4bzkHCm",
        "outputId": "7b76a3f1-644b-4529-a5a3-53a7eda30c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "import caffe2.python.onnx.backend\n",
        "from onnx import helper\n",
        "\n",
        "# Load the ONNX GraphProto object. Graph is a standard Python protobuf object\n",
        "model = onnx.load(\"/content/squeezenet.onnx\")\n",
        "\n",
        "# prepare the caffe2 backend for executing the model this converts the ONNX graph into a\n",
        "# Caffe2 NetDef that can execute it. Other ONNX backends, like one for CNTK will be\n",
        "# availiable soon.\n",
        "prepared_backend = caffe2.python.onnx.backend.prepare(model)\n",
        "\n",
        "# run the model in Caffe2\n",
        "\n",
        "# Construct a map from input names to Tensor data.\n",
        "# The graph itself contains inputs for all weight parameters, followed by the input image.\n",
        "# Since the weights are already embedded, we just need to pass the input image.\n",
        "# last input the grap\n",
        "W = {model.graph.input[0].name: x.data.numpy()}\n",
        "\n",
        "# Run the Caffe2 net:\n",
        "c2_out = prepared_backend.run(W)[0]\n",
        "\n",
        "# Verify the numerical correctness upto 3 decimal places\n",
        "np.testing.assert_almost_equal(torch_out.data.cpu().numpy(), c2_out, decimal=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4d7d11547f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Caffe2 NetDef that can execute it. Other ONNX backends, like one for CNTK will be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# availiable soon.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprepared_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaffe2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# run the model in Caffe2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/caffe2/python/onnx/backend.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(cls, model, device, raw_values_dict, **kwargs)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0mdevice_option\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0minit_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onnx_model_to_caffe2_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_values_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/caffe2/python/onnx/backend.py\u001b[0m in \u001b[0;36m_onnx_model_to_caffe2_net\u001b[0;34m(cls, onnx_model, device, opset_version, include_initializers)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mdevice_option\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolish_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0minit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0mpred_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onnx/utils.py\u001b[0m in \u001b[0;36mpolish_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_doc_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_inference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/onnx/optimizer.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(model, passes, fixed_point)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0moptimized_model_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_fixedpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0moptimized_model_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimized_model_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Input 1 is undefined!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCaZVNMGxzod"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}