{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification_using_python_scikit_and_nltk.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjeetSingh02/Notebooks/blob/master/Text_Classification_using_python_scikit_and_nltk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16N2xiS6gZYr"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zFq-GsRpSjkx",
        "outputId": "9a11c0ab-e3e2-44b6-e3ac-6438bd553444"
      },
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQes_Wo_Sjk3",
        "outputId": "92c12800-56d7-4904-b4a1-107bc73b6fe8"
      },
      "source": [
        "# You can check the target names (categories) and some data files by following commands.\n",
        "twenty_train.target_names"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcI_GPg0Sjk5",
        "outputId": "1bb89e8a-08cc-4c30-c024-96af4ad1695f"
      },
      "source": [
        "i = 0\n",
        "print(twenty_train.data[i])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n",
            "\n",
            " I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "\n",
            "Thanks,\n",
            "- IL\n",
            "   ---- brought to you by your neighborhood Lerxst ----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tFzX9ZWcWp9E",
        "outputId": "13637810-1533-4039-e797-7d0126a8651d"
      },
      "source": [
        "twenty_train.target_names[twenty_train.target[i]]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'rec.autos'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HslrL1eVsQC",
        "outputId": "04d307bf-7ca7-403e-ac58-623439cb55a9"
      },
      "source": [
        "i = 50\n",
        "print(twenty_train.data[i])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: johnc@crsa.bu.edu (John Collins)\n",
            "Subject: Problem with MIT-SHM\n",
            "Organization: Boston University\n",
            "Lines: 27\n",
            "\n",
            "I am trying to write an image display program that uses\n",
            "the MIT shared memory extension.  The shared memory segment\n",
            "gets allocated and attached to the process with no problem.\n",
            "But the program crashes at the first call to XShmPutImage,\n",
            "with the following message:\n",
            "\n",
            "X Error of failed request:  BadShmSeg (invalid shared segment parameter)\n",
            "  Major opcode of failed request:  133 (MIT-SHM)\n",
            "  Minor opcode of failed request:  3 (X_ShmPutImage)\n",
            "  Segment id in failed request 0x0\n",
            "  Serial number of failed request:  741\n",
            "  Current serial number in output stream:  742\n",
            "\n",
            "Like I said, I did error checking on all the calls to shmget\n",
            "and shmat that are necessary to create the shared memory\n",
            "segment, as well as checking XShmAttach.  There are no\n",
            "problems.\n",
            "\n",
            "If anybody has had the same problem or has used MIT-SHM without\n",
            "having the same problem, please let me know.\n",
            "\n",
            "By the way, I am running OpenWindows 3.0 on a Sun Sparc2.\n",
            "\n",
            "Thanks in advance--\n",
            "John C.\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ylngLIGpWG-z",
        "outputId": "05fd32dc-9193-45b1-c9a1-f30409cc413b"
      },
      "source": [
        "twenty_train.target_names[twenty_train.target[i]]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'comp.windows.x'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuSas3vIkJEV",
        "outputId": "5c9df60b-234e-4901-ca66-89c3ed1fb9fe"
      },
      "source": [
        "i = 200\n",
        "print(twenty_train.data[i])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Subject: Re: \"Proper gun control?\" What is proper gun cont\n",
            "From: kim39@scws8.harvard.edu (John Kim)\n",
            "Organization: Harvard University Science Center\n",
            "Nntp-Posting-Host: scws8.harvard.edu\n",
            "Lines: 17\n",
            "\n",
            "In article <C5JGz5.34J@SSD.intel.com> hays@ssd.intel.com (Kirk Hays) writes:\n",
            ">I'd like to point out that I was in error - \"Terminator\" began posting only \n",
            ">six months before he purchased his first firearm, according to private email\n",
            ">from him.\n",
            ">I can't produce an archived posting of his earlier than January 1992,\n",
            ">and he purchased his first firearm in March 1992.\n",
            ">I guess it only seemed like years.\n",
            ">Kirk Hays - NRA Life, seventh generation.\n",
            "\n",
            "I first read and consulted rec.guns in the summer of 1991.  I\n",
            "just purchased my first firearm in early March of this year.\n",
            "\n",
            " NOt for lack of desire for a firearm, you understand.  I could \n",
            "have purchased a rifle or shotgun but didn't want one.\n",
            "-Case Kim\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA3gRUPTkPct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46d6111f-22e5-46af-e2eb-663c683f39e1"
      },
      "source": [
        "twenty_train.target_names[twenty_train.target[i]]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'talk.politics.guns'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMsctQCKmIMW",
        "outputId": "328613aa-8ab5-4dfe-e124-f003647cfc8b"
      },
      "source": [
        "i = 4\n",
        "print(twenty_train.data[i])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: jcm@head-cfa.harvard.edu (Jonathan McDowell)\n",
            "Subject: Re: Shuttle Launch Question\n",
            "Organization: Smithsonian Astrophysical Observatory, Cambridge, MA,  USA\n",
            "Distribution: sci\n",
            "Lines: 23\n",
            "\n",
            "From article <C5owCB.n3p@world.std.com>, by tombaker@world.std.com (Tom A Baker):\n",
            ">>In article <C5JLwx.4H9.1@cs.cmu.edu>, ETRAT@ttacs1.ttu.edu (Pack Rat) writes...\n",
            ">>>\"Clear caution & warning memory.  Verify no unexpected\n",
            ">>>errors. ...\".  I am wondering what an \"expected error\" might\n",
            ">>>be.  Sorry if this is a really dumb question, but\n",
            "> \n",
            "> Parity errors in memory or previously known conditions that were waivered.\n",
            ">    \"Yes that is an error, but we already knew about it\"\n",
            "> I'd be curious as to what the real meaning of the quote is.\n",
            "> \n",
            "> tom\n",
            "\n",
            "\n",
            "My understanding is that the 'expected errors' are basically\n",
            "known bugs in the warning system software - things are checked\n",
            "that don't have the right values in yet because they aren't\n",
            "set till after launch, and suchlike. Rather than fix the code\n",
            "and possibly introduce new bugs, they just tell the crew\n",
            "'ok, if you see a warning no. 213 before liftoff, ignore it'.\n",
            "\n",
            " - Jonathan\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOK14SWDmT-9",
        "outputId": "3a687a52-cbe1-4388-d1fe-d32ab6f486e6"
      },
      "source": [
        "print(twenty_train.target_names[twenty_train.target[i]])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sci.space\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTeE_NY2hGE9"
      },
      "source": [
        "# Extracting Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAPveKp5Sjk5",
        "outputId": "6b06100c-531f-4285-b17d-6df5256d1430"
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShNko4unSjk6",
        "outputId": "6e0569e0-ae39-437d-ee2c-7bcfea73507b"
      },
      "source": [
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9UtufDrhN85"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xeWGnm12Sjk6"
      },
      "source": [
        "# Machine Learning\n",
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGn2x1heSjk6"
      },
      "source": [
        "# Building a pipeline:\n",
        "# The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n",
        "# We will be using the 'text_clf' going forward.\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
        "\n",
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpGirGasSjk7",
        "outputId": "8c8161ea-1a1d-4a5d-c734-5db5e2ba2e78"
      },
      "source": [
        "# Performance of NB Classifier\n",
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7738980350504514"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--_3Xqx4Sjk7",
        "outputId": "a5d74d59-888d-441d-cc2a-4e46cd307ad1"
      },
      "source": [
        "# Training Support Vector Machines - SVM and calculating its performance\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
        "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, random_state=42))])\n",
        "\n",
        "text_clf_svm = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
        "predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
        "np.mean(predicted_svm == twenty_test.target)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8248805098247477"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJlgOahLhlG0"
      },
      "source": [
        "# model train with stop words removal and stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VODee90XSjk-",
        "outputId": "98585905-1d06-4fb5-aeb0-be66c9dd28aa"
      },
      "source": [
        "# Stemming Code\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "\n",
        "class StemmedCountVectorizer(CountVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
        "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
        "    \n",
        "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
        "\n",
        "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
        "                             ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, random_state=42))])\n",
        "\n",
        "text_mnb_stemmed = text_mnb_stemmed.fit(twenty_train.data, twenty_train.target)\n",
        "\n",
        "predicted_mnb_stemmed = text_mnb_stemmed.predict(twenty_test.data)\n",
        "\n",
        "np.mean(predicted_mnb_stemmed == twenty_test.target)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8201009028146574"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm2WywKjiFMj",
        "outputId": "b1c331e1-ea4b-48c2-fee7-f9c7a9d07409"
      },
      "source": [
        "i = 0\n",
        "print(twenty_test.data[i])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. GANDLER)\n",
            "Subject: Need info on 88-89 Bonneville\n",
            "Organization: University at Buffalo\n",
            "Lines: 10\n",
            "News-Software: VAX/VMS VNEWS 1.41\n",
            "Nntp-Posting-Host: ubvmsd.cc.buffalo.edu\n",
            "\n",
            "\n",
            " I am a little confused on all of the models of the 88-89 bonnevilles.\n",
            "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
            "differences are far as features or performance. I am also curious to\n",
            "know what the book value is for prefereably the 89 model. And how much\n",
            "less than book value can you usually get them for. In other words how\n",
            "much are they in demand this time of year. I have heard that the mid-spring\n",
            "early summer is the best time to buy.\n",
            "\n",
            "\t\t\tNeil Gandler\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sQmD6w9id4mW",
        "outputId": "c7a3d66a-7e76-41e4-9054-2c1a98a94544"
      },
      "source": [
        "twenty_train.target_names[predicted_mnb_stemmed[i]]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'rec.autos'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h17u-CvLh5OU",
        "outputId": "f23c15e7-33c2-4606-de66-804f9c106dcb"
      },
      "source": [
        "i = 2\n",
        "print(twenty_test.data[i])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: mathew <mathew@mantis.co.uk>\n",
            "Subject: Re: STRONG & weak Atheism\n",
            "Organization: Mantis Consultants, Cambridge. UK.\n",
            "X-Newsreader: rusnews v1.02\n",
            "Lines: 9\n",
            "\n",
            "acooper@mac.cc.macalstr.edu (Turin Turambar, ME Department of Utter Misery) writes:\n",
            "> Did that FAQ ever got modified to re-define strong atheists as not those who\n",
            "> assert the nonexistence of God, but as those who assert that they BELIEVE in \n",
            "> the nonexistence of God?\n",
            "\n",
            "In a word, yes.\n",
            "\n",
            "\n",
            "mathew\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bi2JpUcTihg3",
        "outputId": "454da2b9-d4ce-4ed1-ecf5-4af6a6df20ad"
      },
      "source": [
        "twenty_train.target_names[predicted_mnb_stemmed[i]]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'alt.atheism'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}