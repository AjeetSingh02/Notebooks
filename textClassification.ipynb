{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textClassification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCPnfzHdESZs2n7ylBH98j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjeetSingh02/Notebooks/blob/master/textClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJIhKUH9FCMX"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rEC4NhS0YSJ"
      },
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9OW1Kom-z23"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPqdDr-t0dW3",
        "outputId": "c3b76488-eb07-4c45-c96e-19baaa44fdd1"
      },
      "source": [
        "# You can check the target names (categories) and some data files by following commands.\n",
        "twenty_train.target_names"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKeF2yjT30x4"
      },
      "source": [
        "atheism_christian_data = []\n",
        "atheism_christian_target = []\n",
        "atheism_christian_target_names = []"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs6YTHCn0lCN"
      },
      "source": [
        "# Taking only two groups currently\n",
        "for i in range(len(twenty_train.target)):\n",
        "    if twenty_train.target[i] == 0 or twenty_train.target[i] == 15:\n",
        "        atheism_christian_data.append(twenty_train.data[i])\n",
        "        atheism_christian_target.append(twenty_train.target[i])\n",
        "        atheism_christian_target_names.append(twenty_train.target_names[twenty_train.target[i]])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhNfqjKA07Iv",
        "outputId": "53b41385-2d23-4160-b39e-941cb1d1edd3"
      },
      "source": [
        "i = 0\n",
        "print(atheism_christian_data[i])\n",
        "print(\"Target Name: \", twenty_train.target_names[atheism_christian_target[i]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: mathew <mathew@mantis.co.uk>\n",
            "Subject: Re: <Political Atheists?\n",
            "Organization: Mantis Consultants, Cambridge. UK.\n",
            "X-Newsreader: rusnews v1.01\n",
            "Lines: 22\n",
            "\n",
            "kmr4@po.CWRU.edu (Keith M. Ryan) writes:\n",
            "> ( I am almost sure that Zyklon-B is immediate and painless method of \n",
            "> death. If not, insert soem other form. )\n",
            "> \n",
            ">         And, ethnic and minority groups have been killed, mutilated and \n",
            "> exterminated through out history, so I guess it was not unusual.\n",
            "> \n",
            ">         So, you would agree that the holocost would be allowed under the US \n",
            "> Constitution?  [ in so far, the punishment. I doubt they recieved what would \n",
            "> be considered a \"fair\" trial by US standards.\n",
            "\n",
            "Don't be so sure.  Look what happened to Japanese citizens in the US during\n",
            "World War II.  If you're prepared to say \"Let's round these people up and\n",
            "stick them in a concentration camp without trial\", it's only a short step to\n",
            "gassing them without trial.  After all, it seems that the Nazis originally\n",
            "only intended to imprison the Jews; the Final Solution was dreamt up partly\n",
            "because they couldn't afford to run the camps because of the devastation\n",
            "caused by Goering's Total War.  Those who weren't gassed generally died of\n",
            "malnutrition or disease.\n",
            "\n",
            "\n",
            "mathew\n",
            "\n",
            "Target Name:  alt.atheism\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N00NxSl4yuv",
        "outputId": "3894faa6-04b0-469b-9df0-ad3aa945cb6a"
      },
      "source": [
        "i = 2\n",
        "print(atheism_christian_data[i])\n",
        "print(\"Target Name: \", twenty_train.target_names[atheism_christian_target[i]])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: jonh@david.wheaton.edu (Jonathan Hayward)\n",
            "Subject: Re: Pantheism & Environmentalism\n",
            "Organization: Wheaton College, IL\n",
            "Lines: 46\n",
            "\n",
            "In article <Apr.5.23.31.36.1993.23919@athos.rutgers.edu> by028@cleveland.freenet.edu (Gary V. Cavano) writes:\n",
            ">I'm new to this group, and maybe this has been covered already,\n",
            ">but does anybody out there see the current emphasis on the\n",
            ">environment being turned (unintentionally, of course) into\n",
            ">pantheism?\n",
            "\n",
            "Yes.\n",
            "\n",
            "(I am adamantly an environmentalist.  I will not use styrofoam table service.\n",
            "Please keep that in mind as you read this post - I do not wish to attack\n",
            "environmentalism)\n",
            "\n",
            "A half truth is at least as dangerous as a complete lie.  A complete lie will\n",
            "rarely be readily accepted, while a half truth (the lie subtly hidden) is more\n",
            "powerfully offered by one who masquerades as an angel of light.\n",
            "\n",
            "Satan has (for some people) loosened the grip on treating the earth as something\n",
            "other than God's intricate handiwork, something other than that on which the\n",
            "health of future generations is based.  It is being treated with respect.  You\n",
            "think he's going to happily leave it at that?  No.  When one error is rejected,\n",
            "it is his style to push people to the opposite error.  Therefore the earth is\n",
            "not God's intricate handiwork, not because it is rubbish, but because it is\n",
            "God.  Mother earth is the one you are to primarily love and serve.\n",
            "\n",
            "I see two facets of a response to it:\n",
            "\n",
            "1: Care for the environment.  Treat it with proper respect, both because it is\n",
            "   God's intricate handiwork and the health of future generation, and because\n",
            "   showing the facet of one who is disregardful of such things does not\n",
            "   constitute what the Apostle Paul called \"becoming all things to all men so\n",
            "   that by all possible means I might save some.\"\n",
            "\n",
            "   Don't say \"Forget the environment, I've got important things to spend my time\n",
            "   on.\" - putting your foot in your mouth in this manner will destroy your\n",
            "   credibility in expressing the things that _are_ more important.\n",
            "\n",
            "2: Show that it is not the ultimate entity, that it is creature and not\n",
            "   creator.  Show that its beauty and glory points to a greater beauty and\n",
            "   glory.  Show that it is not the ultimate tapestry, but one of many cords\n",
            "   woven in the infinite tapestry.\n",
            "\n",
            "################################################################################\n",
            "# \"God, give me mountains # \"But the greatest   # Jonathan Hayward             #\n",
            "# to climb and the        # of these is love.\"  # Jonathan_Hayward@wheaton.edu #\n",
            "# strength for climbing.\" # I Corinthians 13:13 # jhayward@imsa.edu            #\n",
            "################################################################################\n",
            "\n",
            "Target Name:  soc.religion.christian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co9DQOYmFFrn"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9kCxpiX5CXW",
        "outputId": "b45e3673-41df-429f-df3c-7cab891ea43f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "facZBwf86pIQ"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAmeC_dN6xhg"
      },
      "source": [
        "df = pd.DataFrame({\"article\": atheism_christian_data, \n",
        "                    \"target_code\": atheism_christian_target,\n",
        "                    \"taget_name\": atheism_christian_target_names})"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "nx9eHMtx8ET0",
        "outputId": "0f0ad8c2-bbae-4cc7-d818-4e38bfa0ecf4"
      },
      "source": [
        "df[\"target_code\"].where(df[\"target_code\"] == 0, 1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>target_code</th>\n",
              "      <th>taget_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: jonh@david.wheaton.edu (Jonathan Hayward...</td>\n",
              "      <td>1</td>\n",
              "      <td>soc.religion.christian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: dlecoint@garnet.acns.fsu.edu (Darius_Lec...</td>\n",
              "      <td>1</td>\n",
              "      <td>soc.religion.christian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: a137490@lehtori.cc.tut.fi (Aario Sami)\\n...</td>\n",
              "      <td>0</td>\n",
              "      <td>alt.atheism</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             article  ...              taget_name\n",
              "0  From: mathew <mathew@mantis.co.uk>\\nSubject: R...  ...             alt.atheism\n",
              "1  From: keith@cco.caltech.edu (Keith Allan Schne...  ...             alt.atheism\n",
              "2  From: jonh@david.wheaton.edu (Jonathan Hayward...  ...  soc.religion.christian\n",
              "3  From: dlecoint@garnet.acns.fsu.edu (Darius_Lec...  ...  soc.religion.christian\n",
              "4  From: a137490@lehtori.cc.tut.fi (Aario Sami)\\n...  ...             alt.atheism\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzKlzgMC8IXe",
        "outputId": "f9e4f012-f978-4860-8616-12f25942ef23"
      },
      "source": [
        "df.target_code.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    599\n",
              "0    480\n",
              "Name: target_code, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws44QO708VIA"
      },
      "source": [
        "# Tokenization\n",
        "def tokenize_data(dataset):\n",
        "    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
        "    for i in range(dataset.shape[0]):\n",
        "       dataset[\"article\"][i] = tokenizer.tokenize(dataset[\"article\"][i])\n",
        "       \n",
        "    return dataset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGlBcleM9tWI",
        "outputId": "31651836-2797-47e6-f055-1c8b50175509"
      },
      "source": [
        "df = tokenize_data(df)\n",
        "print(df.head())\n",
        "print(df[\"article\"][0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             article  ...              taget_name\n",
            "0  [From, :, mathew, <, mathew, @, mantis.co.uk, ...  ...             alt.atheism\n",
            "1  [From, :, keith, @, cco.caltech.edu, (, Keith,...  ...             alt.atheism\n",
            "2  [From, :, jonh, @, david.wheaton.edu, (, Jonat...  ...  soc.religion.christian\n",
            "3  [From, :, dlecoint, @, garnet.acns.fsu.edu, (,...  ...  soc.religion.christian\n",
            "4  [From, :, a137490, @, lehtori.cc.tut.fi, (, Aa...  ...             alt.atheism\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "['From', ':', 'mathew', '<', 'mathew', '@', 'mantis.co.uk', '>', 'Subject', ':', 'Re', ':', '<', 'Political', 'Atheists', '?', 'Organization', ':', 'Mantis', 'Consultants', ',', 'Cambridge.', 'UK.', 'X-Newsreader', ':', 'rusnews', 'v1.01', 'Lines', ':', '22', 'kmr4', '@', 'po.CWRU.edu', '(', 'Keith', 'M.', 'Ryan', ')', 'writes', ':', '>', '(', 'I', 'am', 'almost', 'sure', 'that', 'Zyklon-B', 'is', 'immediate', 'and', 'painless', 'method', 'of', '>', 'death.', 'If', 'not', ',', 'insert', 'soem', 'other', 'form.', ')', '>', '>', 'And', ',', 'ethnic', 'and', 'minority', 'groups', 'have', 'been', 'killed', ',', 'mutilated', 'and', '>', 'exterminated', 'through', 'out', 'history', ',', 'so', 'I', 'guess', 'it', 'was', 'not', 'unusual.', '>', '>', 'So', ',', 'you', 'would', 'agree', 'that', 'the', 'holocost', 'would', 'be', 'allowed', 'under', 'the', 'US', '>', 'Constitution', '?', '[', 'in', 'so', 'far', ',', 'the', 'punishment.', 'I', 'doubt', 'they', 'recieved', 'what', 'would', '>', 'be', 'considered', 'a', '``', 'fair', \"''\", 'trial', 'by', 'US', 'standards.', 'Do', \"n't\", 'be', 'so', 'sure.', 'Look', 'what', 'happened', 'to', 'Japanese', 'citizens', 'in', 'the', 'US', 'during', 'World', 'War', 'II.', 'If', 'you', \"'re\", 'prepared', 'to', 'say', '``', 'Let', \"'s\", 'round', 'these', 'people', 'up', 'and', 'stick', 'them', 'in', 'a', 'concentration', 'camp', 'without', 'trial', \"''\", ',', 'it', \"'s\", 'only', 'a', 'short', 'step', 'to', 'gassing', 'them', 'without', 'trial.', 'After', 'all', ',', 'it', 'seems', 'that', 'the', 'Nazis', 'originally', 'only', 'intended', 'to', 'imprison', 'the', 'Jews', ';', 'the', 'Final', 'Solution', 'was', 'dreamt', 'up', 'partly', 'because', 'they', 'could', \"n't\", 'afford', 'to', 'run', 'the', 'camps', 'because', 'of', 'the', 'devastation', 'caused', 'by', 'Goering', \"'s\", 'Total', 'War.', 'Those', 'who', 'were', \"n't\", 'gassed', 'generally', 'died', 'of', 'malnutrition', 'or', 'disease.', 'mathew']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PaJ4BR68wDU"
      },
      "source": [
        "# Stop words removal\n",
        "def remove_stop_words(dataset):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    for i in range(dataset.shape[0]):\n",
        "        dataset[\"article\"][i] = ([token.lower() for token in dataset[\"article\"][i] if token not in stop_words])\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSVaTgZ09vzB",
        "outputId": "23a6941d-39fb-41bd-bf4b-f953c3c5e275"
      },
      "source": [
        "df = remove_stop_words(df)\n",
        "print(df.head())\n",
        "print(df[\"article\"][0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             article  ...              taget_name\n",
            "0  [from, :, mathew, <, mathew, @, mantis.co.uk, ...  ...             alt.atheism\n",
            "1  [from, :, keith, @, cco.caltech.edu, (, keith,...  ...             alt.atheism\n",
            "2  [from, :, jonh, @, david.wheaton.edu, (, jonat...  ...  soc.religion.christian\n",
            "3  [from, :, dlecoint, @, garnet.acns.fsu.edu, (,...  ...  soc.religion.christian\n",
            "4  [from, :, a137490, @, lehtori.cc.tut.fi, (, aa...  ...             alt.atheism\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "['from', ':', 'mathew', '<', 'mathew', '@', 'mantis.co.uk', '>', 'subject', ':', 're', ':', '<', 'political', 'atheists', '?', 'organization', ':', 'mantis', 'consultants', ',', 'cambridge.', 'uk.', 'x-newsreader', ':', 'rusnews', 'v1.01', 'lines', ':', '22', 'kmr4', '@', 'po.cwru.edu', '(', 'keith', 'm.', 'ryan', ')', 'writes', ':', '>', '(', 'i', 'almost', 'sure', 'zyklon-b', 'immediate', 'painless', 'method', '>', 'death.', 'if', ',', 'insert', 'soem', 'form.', ')', '>', '>', 'and', ',', 'ethnic', 'minority', 'groups', 'killed', ',', 'mutilated', '>', 'exterminated', 'history', ',', 'i', 'guess', 'unusual.', '>', '>', 'so', ',', 'would', 'agree', 'holocost', 'would', 'allowed', 'us', '>', 'constitution', '?', '[', 'far', ',', 'punishment.', 'i', 'doubt', 'recieved', 'would', '>', 'considered', '``', 'fair', \"''\", 'trial', 'us', 'standards.', 'do', \"n't\", 'sure.', 'look', 'happened', 'japanese', 'citizens', 'us', 'world', 'war', 'ii.', 'if', \"'re\", 'prepared', 'say', '``', 'let', \"'s\", 'round', 'people', 'stick', 'concentration', 'camp', 'without', 'trial', \"''\", ',', \"'s\", 'short', 'step', 'gassing', 'without', 'trial.', 'after', ',', 'seems', 'nazis', 'originally', 'intended', 'imprison', 'jews', ';', 'final', 'solution', 'dreamt', 'partly', 'could', \"n't\", 'afford', 'run', 'camps', 'devastation', 'caused', 'goering', \"'s\", 'total', 'war.', 'those', \"n't\", 'gassed', 'generally', 'died', 'malnutrition', 'disease.', 'mathew']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dApaueM82au"
      },
      "source": [
        "# Normalization\n",
        "def normalize(dataset):\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    for i in range(dataset.shape[0]):\n",
        "        dataset[\"article\"][i] = \" \".join([lemmatizer.lemmatize(token) for token in dataset[\"article\"][i]]).strip()\n",
        "    \n",
        "    return dataset"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA6S6Izn9xKY",
        "outputId": "c3a65a9b-13b2-45c4-d496-4657d5947280"
      },
      "source": [
        "df = normalize(df)\n",
        "print(df.head())\n",
        "print(df[\"article\"][0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             article  ...              taget_name\n",
            "0  from : mathew < mathew @ mantis.co.uk > subjec...  ...             alt.atheism\n",
            "1  from : keith @ cco.caltech.edu ( keith allan s...  ...             alt.atheism\n",
            "2  from : jonh @ david.wheaton.edu ( jonathan hay...  ...  soc.religion.christian\n",
            "3  from : dlecoint @ garnet.acns.fsu.edu ( darius...  ...  soc.religion.christian\n",
            "4  from : a137490 @ lehtori.cc.tut.fi ( aario sam...  ...             alt.atheism\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "from : mathew < mathew @ mantis.co.uk > subject : re : < political atheist ? organization : mantis consultant , cambridge. uk. x-newsreader : rusnews v1.01 line : 22 kmr4 @ po.cwru.edu ( keith m. ryan ) writes : > ( i almost sure zyklon-b immediate painless method > death. if , insert soem form. ) > > and , ethnic minority group killed , mutilated > exterminated history , i guess unusual. > > so , would agree holocost would allowed u > constitution ? [ far , punishment. i doubt recieved would > considered `` fair '' trial u standards. do n't sure. look happened japanese citizen u world war ii. if 're prepared say `` let 's round people stick concentration camp without trial '' , 's short step gassing without trial. after , seems nazi originally intended imprison jew ; final solution dreamt partly could n't afford run camp devastation caused goering 's total war. those n't gassed generally died malnutrition disease. mathew\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56jPUZmL9O0_"
      },
      "source": [
        "# Punctuation and Symbols removal\n",
        "def remove_garbage(dataset):\n",
        "    garbage = \"~`!@#$%^&*()_-+={[}]|\\:;'<,>.?/\"\n",
        "    for i in range(dataset.shape[0]):\n",
        "        dataset[\"article\"][i] = \"\".join([char for char in dataset[\"article\"][i] if char not in garbage])\n",
        "    return dataset"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAulUSIS9frv",
        "outputId": "676dee05-618f-4132-9f42-2b9598704fa2"
      },
      "source": [
        "df = remove_garbage(df)\n",
        "print(df.head())\n",
        "print(df[\"article\"][0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             article  ...              taget_name\n",
            "0  from  mathew  mathew  mantiscouk  subject  re ...  ...             alt.atheism\n",
            "1  from  keith  ccocaltechedu  keith allan schnei...  ...             alt.atheism\n",
            "2  from  jonh  davidwheatonedu  jonathan hayward ...  ...  soc.religion.christian\n",
            "3  from  dlecoint  garnetacnsfsuedu  dariuslecoin...  ...  soc.religion.christian\n",
            "4  from  a137490  lehtoricctutfi  aario sami  sub...  ...             alt.atheism\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "from  mathew  mathew  mantiscouk  subject  re   political atheist  organization  mantis consultant  cambridge uk xnewsreader  rusnews v101 line  22 kmr4  pocwruedu  keith m ryan  writes    i almost sure zyklonb immediate painless method  death if  insert soem form    and  ethnic minority group killed  mutilated  exterminated history  i guess unusual   so  would agree holocost would allowed u  constitution   far  punishment i doubt recieved would  considered  fair  trial u standards do nt sure look happened japanese citizen u world war ii if re prepared say  let s round people stick concentration camp without trial   s short step gassing without trial after  seems nazi originally intended imprison jew  final solution dreamt partly could nt afford run camp devastation caused goering s total war those nt gassed generally died malnutrition disease mathew\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WCCgHOmFS-3"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csBNwSuU_heI"
      },
      "source": [
        "def fit_corpus(train_data):\n",
        "    tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1,6))\n",
        "    tfidf.fit(train_data[\"article\"])\n",
        "    return tfidf"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSleIl4JCCk6"
      },
      "source": [
        "def transform_data(tfidf, dataset):\n",
        "    features = tfidf.transform(dataset[\"article\"])\n",
        "    return pd.DataFrame(features.todense(), columns = tfidf.get_feature_names())"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5RCbAawCOdV"
      },
      "source": [
        "tfidf = fit_corpus(df)  #Fitting the vectorizer\n",
        "train_features = transform_data(tfidf, df)  #transforming \n",
        "train_labels = df[\"target_code\"]  #Taking lables in separate"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "b3iohAc0DN-i",
        "outputId": "1512d645-3701-4273-e90a-8252e9de0083"
      },
      "source": [
        "train_features.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>00 these</th>\n",
              "      <th>00 these opinion</th>\n",
              "      <th>00 these opinion probably</th>\n",
              "      <th>00 these opinion probably show</th>\n",
              "      <th>00 these opinion probably show know</th>\n",
              "      <th>0001</th>\n",
              "      <th>0001 south</th>\n",
              "      <th>0001 south africa</th>\n",
              "      <th>0001 south africa internet</th>\n",
              "      <th>0001 south africa internet hayesstw</th>\n",
              "      <th>0001 south africa internet hayesstw risc1unisaacza</th>\n",
              "      <th>0100</th>\n",
              "      <th>01580</th>\n",
              "      <th>01580 change</th>\n",
              "      <th>01580 change without</th>\n",
              "      <th>01580 change without notice</th>\n",
              "      <th>01580 change without notice when</th>\n",
              "      <th>01580 change without notice when dream</th>\n",
              "      <th>02</th>\n",
              "      <th>02173</th>\n",
              "      <th>02173 are</th>\n",
              "      <th>02173 are 6179812575</th>\n",
              "      <th>02173 are 6179812575 cs</th>\n",
              "      <th>02173 are 6179812575 cs lewis</th>\n",
              "      <th>04</th>\n",
              "      <th>04 tsakc</th>\n",
              "      <th>04 tsakc my</th>\n",
              "      <th>04 tsakc my thought</th>\n",
              "      <th>04 tsakc my thought post</th>\n",
              "      <th>04 tsakc my thought post idea</th>\n",
              "      <th>0500</th>\n",
              "      <th>0500 from</th>\n",
              "      <th>0500 from nanci</th>\n",
              "      <th>0500 from nanci ann</th>\n",
              "      <th>0500 from nanci ann miller</th>\n",
              "      <th>0500 from nanci ann miller nm0w</th>\n",
              "      <th>051018</th>\n",
              "      <th>051018 gmt</th>\n",
              "      <th>051018 gmt bobbe</th>\n",
              "      <th>...</th>\n",
              "      <th>yoyoccmonasheduau fred rice wrote</th>\n",
              "      <th>yugoslavia</th>\n",
              "      <th>zaphodmpsohiostateedu</th>\n",
              "      <th>zaphodmpsohiostateedu wupost</th>\n",
              "      <th>zaphodmpsohiostateedu wupost uunet</th>\n",
              "      <th>zaphodmpsohiostateedu wupost uunet olivea</th>\n",
              "      <th>zaphodmpsohiostateedu wupost uunet olivea sgigate</th>\n",
              "      <th>zaphodmpsohiostateedu wupost uunet olivea sgigate odin</th>\n",
              "      <th>zazen</th>\n",
              "      <th>zazen austinibmcom</th>\n",
              "      <th>zazen austinibmcom welbon</th>\n",
              "      <th>zazen austinibmcom welbon there</th>\n",
              "      <th>zazen austinibmcom welbon there mean</th>\n",
              "      <th>zazen austinibmcom welbon there mean possibly</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zealand line</th>\n",
              "      <th>zebedee</th>\n",
              "      <th>zebedee certainly</th>\n",
              "      <th>zebedee certainly rome</th>\n",
              "      <th>zebedee certainly rome hand</th>\n",
              "      <th>zebedee certainly rome hand first</th>\n",
              "      <th>zebedee certainly rome hand first martyr</th>\n",
              "      <th>zechariah</th>\n",
              "      <th>zen</th>\n",
              "      <th>zen buddhist</th>\n",
              "      <th>zeuscalpolyedu</th>\n",
              "      <th>zeuscalpolyedu jmunch</th>\n",
              "      <th>zeuscalpolyedu jmunch hertzeleecalpolyedu</th>\n",
              "      <th>zeuscalpolyedu jmunch hertzeleecalpolyedu john</th>\n",
              "      <th>zeuscalpolyedu jmunch hertzeleecalpolyedu john munch</th>\n",
              "      <th>zeuscalpolyedu jmunch hertzeleecalpolyedu john munch wrote</th>\n",
              "      <th>zillion</th>\n",
              "      <th>zlumber</th>\n",
              "      <th>zoerasterism</th>\n",
              "      <th>zoerasterism shintoism</th>\n",
              "      <th>zoerasterism shintoism islam</th>\n",
              "      <th>zoerasterism shintoism islam fit</th>\n",
              "      <th>zoerasterism shintoism islam fit bit</th>\n",
              "      <th>zoerasterism shintoism islam fit bit logic</th>\n",
              "      <th>zwart</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 128016 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    00  00 these  ...  zoerasterism shintoism islam fit bit logic  zwart\n",
              "0  0.0       0.0  ...                                         0.0    0.0\n",
              "1  0.0       0.0  ...                                         0.0    0.0\n",
              "2  0.0       0.0  ...                                         0.0    0.0\n",
              "3  0.0       0.0  ...                                         0.0    0.0\n",
              "4  0.0       0.0  ...                                         0.0    0.0\n",
              "\n",
              "[5 rows x 128016 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFOFw8Z9FyhY",
        "outputId": "79c89900-1ba8-4071-94bf-9d44a6b39b0b"
      },
      "source": [
        "train_labels.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    1\n",
              "3    1\n",
              "4    0\n",
              "Name: target_code, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9SIwip0L3U7"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_features, train_labels, test_size=0.30, random_state=23)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6esdWdRMA9B",
        "outputId": "27672a66-2323-4a84-cb3e-acc06da0a2ef"
      },
      "source": [
        "print(train_features.shape)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1079, 128016)\n",
            "(755, 128016) (755,) (324, 128016) (324,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxkdw67FE81L"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM6r0vtlYax7"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN7nQYuWFY1v",
        "outputId": "397fa152-df49-4d9a-a908-fb23b1ca1cd4"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logisticClassifier = LogisticRegression(random_state=0, solver='lbfgs')\n",
        "logisticClassifier.fit(X_train, y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvkFUZ_zNbAq"
      },
      "source": [
        "predictions = logisticClassifier.predict(X_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEdSZ0ArQp6m",
        "outputId": "c97c2d6f-b2b0-456f-b4f9-f22e55ccca85"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 0 1 0 1 1]\n",
            "[1 1 1 1 1 0 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meYB8PSEQtTY",
        "outputId": "63d14be0-7f06-4765-ba2e-f811e7ddaf9d"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.941358024691358"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBH-FPJ_Yqti"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXPl_qk1YfOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "852e3ded-1279-4fda-cb91-8e436276d7b7"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "multinomialClassifier = MultinomialNB()\n",
        "multinomialClassifier.fit(X_train, y_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BQ_WbUCZB7a"
      },
      "source": [
        "predictions = multinomialClassifier.predict(X_test)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABQiMWZxZEFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89acbf16-7cec-422f-866f-5a3cbede71d3"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 0 1 0 1 1]\n",
            "[1 1 1 1 1 0 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eWlAhOZZFKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4465e3c8-0ca1-42a9-8696-c9a2be35b13e"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9753086419753086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnrkMqK-eqAe"
      },
      "source": [
        "## Support vector machines - SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4lZXQ59epgA",
        "outputId": "ad0510f2-50da-4d61-bf00-d734c0ea0790"
      },
      "source": [
        "# Training Support Vector Machines - SVM and calculating its performance\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "svmClassifier = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, random_state=42)\n",
        "svmClassifier.fit(X_train, y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=5,\n",
              "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
              "              random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1,\n",
              "              verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1LnfKSffuRo"
      },
      "source": [
        "predictions = svmClassifier.predict(X_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_y33P-PWf0EZ",
        "outputId": "729508fb-c1bb-415c-a6a6-3c5568094c21"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 0 1 0 1 1]\n",
            "[1 1 1 1 1 0 1 0 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x89WDk_Tf6oY",
        "outputId": "9e883b5b-6577-4be0-b169-8c0aac49a80f"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9660493827160493"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZh_2I9fRPYt"
      },
      "source": [
        "## Support vector machines - Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXPRni5NSMHM"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "linearSvmClassifier = SVC(kernel=\"linear\", C=0.025)\n",
        "linearSvmClassifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJix0p-tkVMH"
      },
      "source": [
        "predictions = linearSvmClassifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6EmByzUkXW3"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHLaLRZwkVQu"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmJ2tWaDmGSC"
      },
      "source": [
        "## Support vector machines - RBF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkpurxwWmRM2"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "rbfSvmClassifier = SVC(gamma=2, C=1)\n",
        "rbfSvmClassifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05kXqCh4mm1n"
      },
      "source": [
        "predictions = rbfSvmClassifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OCOaFVqmm6B"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXQoq9Psmm9d"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw-cY3MKR3Vf"
      },
      "source": [
        "## Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1f7xuh_SLHr"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knnClassifier = KNeighborsClassifier()\n",
        "knnClassifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLtvomo-kb3Y"
      },
      "source": [
        "predictions = knnClassifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZQi3XVLkb7g"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3rVDx5Ckb_u"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJtmgaT_R3gs"
      },
      "source": [
        "## Gaussian Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcTuDGWaSM71"
      },
      "source": [
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "\n",
        "GPClassifier = GaussianProcessClassifier(1.0 * RBF(1.0))\n",
        "GPClassifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfwNRZX0kccS"
      },
      "source": [
        "predictions = GPClassifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3yqfr2dkcgG"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27_FMiXGkcjV"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v9gHg7PR3mQ"
      },
      "source": [
        "## AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTs2TKdSSNbH"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "adaClassifier = AdaBoostClassifier()\n",
        "adaClassifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XltPRQ2FkdEm"
      },
      "source": [
        "predictions = adaClassifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkgffLI9kdIW"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCQgBxtzkdL3"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VklP4gIR3q8"
      },
      "source": [
        "## QDA (QuadraticDiscriminantAnalysis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z7Cvr3xSNzV"
      },
      "source": [
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "quadClassifier = QuadraticDiscriminantAnalysis()\n",
        "quadClassifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd1ftoZPkdpH"
      },
      "source": [
        "predictions = quadClassifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz_9gJOpkdsX"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFp_mznvkdva"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-XQkoxKJzyC"
      },
      "source": [
        "## Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg5xgTsSJ3zS"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decisionClassifier = DecisionTreeClassifier(random_state=23)\n",
        "decisionClassifier.fit(X_train, y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l6nOEmXLPEN"
      },
      "source": [
        "predictions = decisionClassifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr_2gTaFLS6r"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSB7qytvLVLc"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM1aOupRLveQ"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfMRi6VoLx06"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfClassifier = RandomForestClassifier(random_state=23)\n",
        "rfClassifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WASQMoj0Mjh4"
      },
      "source": [
        "predictions = rfClassifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtf8MgxzM6AW"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwV3xFbBM7eN"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhAog9tMSDIv"
      },
      "source": [
        "## Neural Net (sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iCGPsoASG0N"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "nnClassifier = MLPClassifier(alpha=1, max_iter=1000)\n",
        "nnClassifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmTchxC0ntn7"
      },
      "source": [
        "predictions = nnClassifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8UrLDMxntsP"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i60C_50ntvu"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HagsSzm1lumt"
      },
      "source": [
        "## XGboost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btB_Mh9Slwnd"
      },
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frj7OebEsLSN"
      },
      "source": [
        "D_train = xgb.DMatrix(X_train, label=y_train)\n",
        "D_test = xgb.DMatrix(X_test, label=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE1_DWv0sS_e"
      },
      "source": [
        "param = {\n",
        "    'eta': 0.3, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 3} \n",
        "\n",
        "steps = 100  # The number of training iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIPekexgsU4w"
      },
      "source": [
        "xgb = XGBClassifier(n_estimators=100)\n",
        "xgb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6BYrC7_sYHG"
      },
      "source": [
        "predictions = xgb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvpiV2SFsat6"
      },
      "source": [
        "print(predictions[:10])\n",
        "print(y_test.values[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRqteVt1scLr"
      },
      "source": [
        "np.mean(predictions == y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}