{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Snorkel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjeetSingh02/Notebooks/blob/master/Snorkel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf97rvlJKE_Y",
        "colab_type": "code",
        "outputId": "607517d3-990e-4f81-e8f6-c467716c8145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# !pip install snorkel"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: snorkel in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from snorkel) (1.3.1)\n",
            "Requirement already satisfied: tensorboardX<2.0,>=1.6 in /usr/local/lib/python3.6/dist-packages (from snorkel) (1.8)\n",
            "Requirement already satisfied: pandas<0.25.0,>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from snorkel) (0.24.2)\n",
            "Requirement already satisfied: torch<1.2.0,>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from snorkel) (1.1.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.29.0 in /usr/local/lib/python3.6/dist-packages (from snorkel) (4.36.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from snorkel) (1.16.5)\n",
            "Requirement already satisfied: networkx<3.0,>=2.2 in /usr/local/lib/python3.6/dist-packages (from snorkel) (2.3)\n",
            "Requirement already satisfied: scikit-learn<0.22.0,>=0.20.2 in /usr/local/lib/python3.6/dist-packages (from snorkel) (0.21.3)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX<2.0,>=1.6->snorkel) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX<2.0,>=1.6->snorkel) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas<0.25.0,>=0.24.0->snorkel) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas<0.25.0,>=0.24.0->snorkel) (2.5.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx<3.0,>=2.2->snorkel) (4.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn<0.22.0,>=0.20.2->snorkel) (0.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX<2.0,>=1.6->snorkel) (41.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9EYbA3DlZ3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from snorkel.labeling import labeling_function\n",
        "from snorkel.labeling import LabelingFunction\n",
        "from sklearn.model_selection import train_test_split\n",
        "from snorkel.labeling import PandasLFApplier\n",
        "from snorkel.labeling import LFAnalysis\n",
        "from snorkel.preprocess import preprocessor\n",
        "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
        "from snorkel.labeling import LabelModel\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from snorkel.analysis import get_label_buckets\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-p2NxWpscW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run this cell to load dataset into df_train, df_dev, df_valid, df_test\n",
        "data = pd.read_csv(\"/content/Youtube 01-comments Psy.csv\", sep=\",\", usecols=[\"CONTENT\",\"CLASS\"])\n",
        "data = data.append(pd.read_csv(\"/content/Youtube 04-comments KatyPerry.csv\", sep=\",\", usecols=[\"CONTENT\",\"CLASS\"]), ignore_index=True)\n",
        "data = data.append(pd.read_csv(\"/content/Youtube 07-comments LMFAO.csv\", sep=\",\", usecols=[\"CONTENT\",\"CLASS\"]), ignore_index=True)\n",
        "df_train = data.append(pd.read_csv(\"/content/Youtube 08-comments Eminem.csv\", sep=\",\", usecols=[\"CONTENT\",\"CLASS\"]), ignore_index=True)\n",
        "\n",
        "df_dev = df_train.sample(200)\n",
        "df_dev.reset_index(inplace=True, drop=True)\n",
        "df_train.drop(columns=[\"CLASS\"], inplace=True)\n",
        "\n",
        "data = pd.read_csv(\"/content/Youtube 09-comments Shakira.csv\", sep=\",\", usecols=[\"CONTENT\",\"CLASS\"])\n",
        "df_valid, df_test = train_test_split(data, test_size=0.5, random_state=42)\n",
        "df_valid.reset_index(inplace=True, drop=True)\n",
        "df_test.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zZ-6h1fwgaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pulling the label vectors for ease of use later\n",
        "Y_dev = df_dev.CLASS.values\n",
        "Y_valid = df_valid.CLASS.values\n",
        "Y_test = df_test.CLASS.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0SstHL2yZvY",
        "colab_type": "code",
        "outputId": "86262c97-18bd-4e9d-baca-f1a336f2ad8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# For clarity, we define constants to represent the class labels for spam, ham, and abstaining.\n",
        "ABSTAIN = -1\n",
        "HAM = 0\n",
        "SPAM = 1\n",
        "\n",
        "print(f\"Dev SPAM frequency: {100 * (df_dev.CLASS.values == SPAM).mean():.1f}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dev SPAM frequency: 54.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki2InslsDDFV",
        "colab_type": "code",
        "outputId": "81aff3b3-00d2-415f-af76-cf4687eeae3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_dev.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CONTENT</th>\n",
              "      <th>CLASS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Check out this video on YouTube:﻿</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'm here to check the views.. holy shit﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Love﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2 billion views, only 2 million shares﻿</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Check out our Channel for nice Beats!!﻿</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    CONTENT  CLASS\n",
              "0         Check out this video on YouTube:﻿      1\n",
              "1  I'm here to check the views.. holy shit﻿      0\n",
              "2                                     Love﻿      0\n",
              "3   2 billion views, only 2 million shares﻿      0\n",
              "4   Check out our Channel for nice Beats!!﻿      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEaC99k9yjef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Writing LFs to identify spammy comments that use the phrase “check out” and \"check\"\n",
        "@labeling_function()\n",
        "def check(x):\n",
        "    return SPAM if \"check\" in x.CONTENT.lower() else ABSTAIN\n",
        "\n",
        "\n",
        "@labeling_function()\n",
        "def check_out(x):\n",
        "    return SPAM if \"check out\" in x.CONTENT.lower() else ABSTAIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u7HQmwWB7Ri",
        "colab_type": "code",
        "outputId": "e90a9f92-7f41-4ad3-cce5-ec13caf8ab27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# applying one or more LFs that we’ve written to a collection of data points\n",
        "# The output of the apply(...) method is a label matrix\n",
        "# It’s a NumPy array L with one column for each LF and one row for each data point\n",
        "\n",
        "lfs = [check_out, check]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)\n",
        "L_dev = applier.apply(df=df_dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1586/1586 [00:00<00:00, 22406.47it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 5904.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujOFwun2Dtak",
        "colab_type": "code",
        "outputId": "a84b924b-9d25-4cea-dc4d-d5583a7e451d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "L_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  1],\n",
              "       [ 1,  1],\n",
              "       [-1, -1],\n",
              "       ...,\n",
              "       [-1, -1],\n",
              "       [-1, -1],\n",
              "       [-1, -1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiUWtvKYD2Yl",
        "colab_type": "code",
        "outputId": "173159c9-141c-47f8-f8ea-5e2457f21c8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_train.CONTENT[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Huh, anyway check out this you[tube] channel: kobyoshi02'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7QILvteD_U0",
        "colab_type": "code",
        "outputId": "201eeab5-2069-4462-dd41-c4e969a5dedb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Coverage of these LFs \n",
        "\n",
        "coverage_check_out, coverage_check = (L_train != ABSTAIN).mean(axis=0)\n",
        "print(f\"check_out coverage: {coverage_check_out * 100:.1f}%\")\n",
        "print(f\"check coverage: {coverage_check * 100:.1f}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check_out coverage: 21.4%\n",
            "check coverage: 25.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xecA5wPEqsF",
        "colab_type": "code",
        "outputId": "f141135c-187b-4d96-8951-6d384de74625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# LF analyses using the LFAnalysis utility.\n",
        "\n",
        "'Polarity:' #The set of unique labels this LF outputs (excluding abstains)\n",
        "'Coverage:' #The fraction of the dataset the LF labels\n",
        "'Overlaps:' #The fraction of the dataset where this LF and at least one other LF label\n",
        "'Conflicts:' #The fraction of the dataset where this LF and at least one other LF label and disagree\n",
        "'Correct:' #The number of data points this LF labels correctly (if gold labels are provided)\n",
        "'Incorrect:' #The number of data points this LF labels incorrectly (if gold labels are provided)\n",
        "'Empirical Accuracy:' #The empirical accuracy of this LF (if gold labels are provided)\n",
        "\n",
        "\n",
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>check_out</th>\n",
              "      <td>0</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.214376</td>\n",
              "      <td>0.214376</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>check</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.257881</td>\n",
              "      <td>0.214376</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           j Polarity  Coverage  Overlaps  Conflicts\n",
              "check_out  0      [1]  0.214376  0.214376        0.0\n",
              "check      1      [1]  0.257881  0.214376        0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtbiGES7Ig6r",
        "colab_type": "code",
        "outputId": "bc5b115c-2341-4801-c97a-b7c9a53663bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "#passing dev dataset as it has gold labels\n",
        "\n",
        "LFAnalysis(L=L_dev, lfs=lfs).lf_summary(Y=Y_dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Incorrect</th>\n",
              "      <th>Emp. Acc.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>check_out</th>\n",
              "      <td>0</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>check</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53</td>\n",
              "      <td>3</td>\n",
              "      <td>0.946429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           j Polarity  Coverage  ...  Correct  Incorrect  Emp. Acc.\n",
              "check_out  0      [1]      0.23  ...       46          0   1.000000\n",
              "check      1      [1]      0.28  ...       53          3   0.946429\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbcoxXfcJLw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#regular expressions to get the coverage of check plus the accuracy of check_out.\n",
        "\n",
        "import re\n",
        "\n",
        "@labeling_function()\n",
        "def regex_check_out(x):\n",
        "    return SPAM if re.search(r\"check.*out\", x.CONTENT, flags=re.I) else ABSTAIN\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZUC9NbBJxKI",
        "colab_type": "code",
        "outputId": "77da942b-7226-4aca-c1d8-55177c9aed20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "lfs = [check_out, check, regex_check_out]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)\n",
        "L_dev = applier.apply(df=df_dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1586/1586 [00:00<00:00, 16597.76it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 11672.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owDpm5WMJ1l9",
        "colab_type": "code",
        "outputId": "71b4bf70-99c8-46b0-8684-cd83ef0d7a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "L_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  1,  1],\n",
              "       [ 1,  1,  1],\n",
              "       [-1, -1, -1],\n",
              "       ...,\n",
              "       [-1, -1, -1],\n",
              "       [-1, -1, -1],\n",
              "       [-1, -1, -1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fvoU4yLKDGa",
        "colab_type": "code",
        "outputId": "b079bf72-5738-4cdb-f920-c29e3cfbdc35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>check_out</th>\n",
              "      <td>0</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.214376</td>\n",
              "      <td>0.214376</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>check</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.257881</td>\n",
              "      <td>0.233922</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>regex_check_out</th>\n",
              "      <td>2</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.233922</td>\n",
              "      <td>0.233922</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 j Polarity  Coverage  Overlaps  Conflicts\n",
              "check_out        0      [1]  0.214376  0.214376        0.0\n",
              "check            1      [1]  0.257881  0.233922        0.0\n",
              "regex_check_out  2      [1]  0.233922  0.233922        0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XcWghkUKHNo",
        "colab_type": "code",
        "outputId": "6b9db87a-1bb8-40da-879e-904cac6519e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "LFAnalysis(L_dev, lfs).lf_summary(Y=Y_dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Incorrect</th>\n",
              "      <th>Emp. Acc.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>check_out</th>\n",
              "      <td>0</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>check</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.280</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53</td>\n",
              "      <td>3</td>\n",
              "      <td>0.946429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>regex_check_out</th>\n",
              "      <td>2</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 j Polarity  Coverage  ...  Correct  Incorrect  Emp. Acc.\n",
              "check_out        0      [1]     0.230  ...       46          0   1.000000\n",
              "check            1      [1]     0.280  ...       53          3   0.946429\n",
              "regex_check_out  2      [1]     0.265  ...       53          0   1.000000\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e44e4Y1KKv-D",
        "colab_type": "text"
      },
      "source": [
        "<h1>Writing an LF that uses a third-party model</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9aOEJ_7KzU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We’ll start by creating a Preprocessor that runs TextBlob on our comments, then extracts \n",
        "#the polarity and subjectivity scores.\n",
        "\n",
        "@preprocessor(memoize=True)\n",
        "def textblob_sentiment(x):\n",
        "    scores = TextBlob(x.CONTENT)\n",
        "    x.polarity = scores.sentiment.polarity\n",
        "    x.subjectivity = scores.sentiment.subjectivity\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMQKzg05N1jY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We’ll tune the output of our LFs based on the TextBlob scores.\n",
        "\n",
        "@labeling_function(pre=[textblob_sentiment])\n",
        "def textblob_polarity(x):\n",
        "    return HAM if x.polarity > 0.9 else ABSTAIN\n",
        "\n",
        "@labeling_function(pre=[textblob_sentiment])\n",
        "def textblob_subjectivity(x):\n",
        "    return HAM if x.subjectivity >= 0.5 else ABSTAIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bySYJ8hPOpG5",
        "colab_type": "code",
        "outputId": "0867d08d-4fbd-4e75-ade6-823ce7a3c161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#The process: 1st the applier will try to apply LF \"textblob_polarity\" over L_train. But since on top of \n",
        "# \"textblob_polarity\" we have a decorator, it will apply the preprocessor \"textblob_sentiment\" on the datapoint.\n",
        "#The resultant will be a new datapoint with two attributes: sunjectivity and polarity. Now based on that\n",
        "#The LF \"textblob_polarity\" will identify HAM or not\n",
        "\n",
        "lfs = [textblob_polarity, textblob_subjectivity]\n",
        "\n",
        "applier = PandasLFApplier(lfs)\n",
        "L_train = applier.apply(df_train)\n",
        "L_dev = applier.apply(df_dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1586/1586 [00:01<00:00, 824.11it/s]\n",
            "100%|██████████| 200/200 [00:00<00:00, 830.10it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG9yVMgAPSoR",
        "colab_type": "code",
        "outputId": "10b3f219-4302-4c20-d0fe-343f6d891b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "LFAnalysis(L_train, lfs).lf_summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>textblob_polarity</th>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.035309</td>\n",
              "      <td>0.013871</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_subjectivity</th>\n",
              "      <td>1</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.357503</td>\n",
              "      <td>0.013871</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       j Polarity  Coverage  Overlaps  Conflicts\n",
              "textblob_polarity      0      [0]  0.035309  0.013871        0.0\n",
              "textblob_subjectivity  1      [0]  0.357503  0.013871        0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPShcF8EPVfM",
        "colab_type": "code",
        "outputId": "051104f4-1ed9-49c7-a56f-24b572156983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "LFAnalysis(L_dev, lfs).lf_summary(Y=Y_dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Incorrect</th>\n",
              "      <th>Emp. Acc.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>textblob_polarity</th>\n",
              "      <td>0</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_subjectivity</th>\n",
              "      <td>1</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41</td>\n",
              "      <td>29</td>\n",
              "      <td>0.585714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       j Polarity  Coverage  ...  Correct  Incorrect  Emp. Acc.\n",
              "textblob_polarity      0      [0]      0.04  ...        7          1   0.875000\n",
              "textblob_subjectivity  1      [0]      0.35  ...       41         29   0.585714\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coGs8wuZPxZB",
        "colab_type": "text"
      },
      "source": [
        "<h1>Writing More Labeling Functions</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6jaUQNzPa2T",
        "colab_type": "text"
      },
      "source": [
        "No single LF has high enough coverage to label our entire test dataset accurately. If it was then wouldn’t need a classifier at all. We could just use that single simple heuristic to complete the task. <br><br>\n",
        "We usually need to combine multiple LFs to label our dataset, both to increase the size of the generated training set (since we can’t generate training labels for data points that all LFs abstained on) and to improve the overall accuracy of the training labels we generate by factoring in multiple different signals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y3BubtORcGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Keyword LFs'''\n",
        "\n",
        "#This is very intuitive\n",
        "#what we are doing here is instead of creating separate function to search for each type of keyword(for example, please) we are creating tempate\n",
        "#which will take in a type of keywords and then make a function for those keywords. \n",
        "\n",
        "def keyword_lookup(x, keywords, label):\n",
        "    if any(word in x.CONTENT.lower() for word in keywords):\n",
        "        return label\n",
        "    return ABSTAIN\n",
        "\n",
        "\n",
        "def make_keyword_lf(keywords, label=SPAM):\n",
        "    return LabelingFunction(\n",
        "        name=f\"keyword_{keywords[0]}\",\n",
        "        f=keyword_lookup,\n",
        "        resources=dict(keywords=keywords, label=label),\n",
        "    )\n",
        "\n",
        "\n",
        "#Spam comments talk about 'my channel', 'my video', etc.\n",
        "keyword_my = make_keyword_lf(keywords=[\"my\"])\n",
        "\n",
        "#Spam comments ask users to subscribe to their channels.\n",
        "keyword_subscribe = make_keyword_lf(keywords=[\"subscribe\"])\n",
        "\n",
        "#Spam comments post links to other channels.\n",
        "keyword_link = make_keyword_lf(keywords=[\"http\"])\n",
        "\n",
        "#Spam comments make requests rather than commenting.\n",
        "keyword_please = make_keyword_lf(keywords=[\"please\", \"plz\"])\n",
        "\n",
        "#Ham comments actually talk about the video's content.\n",
        "keyword_song = make_keyword_lf(keywords=[\"song\"], label=HAM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWbOSf0lTpa7",
        "colab_type": "code",
        "outputId": "75aad1ee-89e2-4975-f0f7-3b71358db375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''Pattern-matching LFs (regular expressions)'''\n",
        "#If we want a little more control over a keyword search, we can look for regular expressions instead. ]\n",
        "#The LF we developed above (regex_check_out) is an example of this."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pattern-matching LFs (regular expressions)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJrxGNpYT4d4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Heuristic LFs'''\n",
        "#There may other heuristics or “rules of thumb” that you come up with as you look at the data. \n",
        "#So long as you can express it in a function, it’s a viable LF!\n",
        "\n",
        "@labeling_function()\n",
        "def short_comment(x):\n",
        "    \"\"\"Ham comments are often short, such as 'cool video!'\"\"\"\n",
        "    return HAM if len(x.CONTENT.split()) < 5 else ABSTAIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3cwCIc0UEgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''LFs with Complex Preprocessors'''\n",
        "#We can enrich our data (providing more fields for the LFs to refer to) using Preprocessors.\n",
        "\n",
        "#Using Spacy to add lemmas, part-of-speech (pos) tags, etc. to each token\n",
        "#can also add other NLTK libraries\n",
        "\n",
        "\n",
        "# The SpacyPreprocessor parses the text in text_field and\n",
        "# stores the new enriched representation in doc_field\n",
        "spacy = SpacyPreprocessor(text_field=\"CONTENT\", doc_field=\"doc\", memoize=True)\n",
        "\n",
        "\n",
        "@labeling_function(pre=[spacy])\n",
        "def has_person(x):\n",
        "    \"\"\"Ham comments mention specific people and are short.\"\"\"\n",
        "    if len(x.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in x.doc.ents]):\n",
        "        return HAM\n",
        "    else:\n",
        "        return ABSTAIN\n",
        "\n",
        "\n",
        "#same thing below. Just predifined function than manual above\n",
        "\n",
        "# from snorkel.labeling.lf.nlp import nlp_labeling_function\n",
        "# @nlp_labeling_function()\n",
        "# def has_person_nlp(x):\n",
        "#     \"\"\"Ham comments mention specific people and are short.\"\"\"\n",
        "#     if len(x.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in x.doc.ents]):\n",
        "#         return HAM\n",
        "#     else:\n",
        "#         return ABSTAIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCb5Ik-yVY2L",
        "colab_type": "code",
        "outputId": "7f730eee-933b-42b3-bb5c-f0dedb06515d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''Third-party Model LFs'''\n",
        "#We can also utilize other models, including ones trained for other tasks that are related to, but not the same as, the one we care about. \n",
        "#The TextBlob-based LFs we created above are great examples of this!"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Third-party Model LFs'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdtndY86WRpW",
        "colab_type": "text"
      },
      "source": [
        "<h1>Combining Labeling Function Outputs with the Label Model</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxy7B-2zWY0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lfs = [\n",
        "    keyword_my,\n",
        "    keyword_subscribe,\n",
        "    keyword_link,\n",
        "    keyword_please,\n",
        "    keyword_song,\n",
        "    regex_check_out,\n",
        "    short_comment,\n",
        "    has_person,\n",
        "    textblob_polarity,\n",
        "    textblob_subjectivity,\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ5WRLLNYlwl",
        "colab_type": "code",
        "outputId": "7dab084c-260c-429a-e368-0fed11a7691b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)\n",
        "L_dev = applier.apply(df=df_dev)\n",
        "L_valid = applier.apply(df=df_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1586/1586 [00:21<00:00, 74.79it/s]\n",
            "100%|██████████| 200/200 [00:02<00:00, 81.60it/s]\n",
            "100%|██████████| 185/185 [00:02<00:00, 68.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMKeHxm-dKnx",
        "colab_type": "code",
        "outputId": "272c76b2-7133-42d3-b9eb-8b62beb037fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "L_train[10:20]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1,  1, -1, -1, -1, -1,  0, -1, -1, -1],\n",
              "       [-1,  1, -1, -1, -1, -1, -1, -1, -1,  0],\n",
              "       [-1, -1,  1, -1, -1, -1,  0, -1, -1, -1],\n",
              "       [-1,  1, -1, -1, -1, -1,  0, -1, -1, -1],\n",
              "       [-1, -1,  1,  1, -1, -1,  0, -1,  0,  0],\n",
              "       [-1,  1, -1,  1, -1,  1, -1, -1, -1,  0],\n",
              "       [-1, -1, -1, -1, -1, -1, -1, -1, -1,  0],\n",
              "       [-1, -1,  1, -1, -1, -1,  0, -1, -1, -1],\n",
              "       [-1, -1,  1, -1, -1, -1,  0, -1, -1, -1],\n",
              "       [-1, -1, -1, -1, -1, -1, -1, -1, -1,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivO4wSSGbRC4",
        "colab_type": "code",
        "outputId": "25b5fd62-27e7-4373-eca1-307c23e10c1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "LFAnalysis(L=L_dev, lfs=lfs).lf_summary(Y=Y_dev)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>j</th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Incorrect</th>\n",
              "      <th>Emp. Acc.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>keyword_my</th>\n",
              "      <td>0</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.210</td>\n",
              "      <td>0.095</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.837209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_subscribe</th>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.045</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>0.966667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_http</th>\n",
              "      <td>2</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.115</td>\n",
              "      <td>0.095</td>\n",
              "      <td>0.075</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>0.869565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_please</th>\n",
              "      <td>3</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.035</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>keyword_song</th>\n",
              "      <td>4</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.140</td>\n",
              "      <td>0.110</td>\n",
              "      <td>0.040</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>regex_check_out</th>\n",
              "      <td>5</td>\n",
              "      <td>[1]</td>\n",
              "      <td>0.265</td>\n",
              "      <td>0.160</td>\n",
              "      <td>0.090</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>short_comment</th>\n",
              "      <td>6</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.215</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.055</td>\n",
              "      <td>32</td>\n",
              "      <td>11</td>\n",
              "      <td>0.744186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>has_person</th>\n",
              "      <td>7</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.065</td>\n",
              "      <td>0.030</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>0.733333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_polarity</th>\n",
              "      <td>8</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.010</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>textblob_subjectivity</th>\n",
              "      <td>9</td>\n",
              "      <td>[0]</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.275</td>\n",
              "      <td>0.160</td>\n",
              "      <td>41</td>\n",
              "      <td>29</td>\n",
              "      <td>0.585714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       j Polarity  Coverage  ...  Correct  Incorrect  Emp. Acc.\n",
              "keyword_my             0      [1]     0.215  ...       36          7   0.837209\n",
              "keyword_subscribe      1      [1]     0.150  ...       29          1   0.966667\n",
              "keyword_http           2      [1]     0.115  ...       20          3   0.869565\n",
              "keyword_please         3      [1]     0.135  ...       27          0   1.000000\n",
              "keyword_song           4      [0]     0.140  ...       21          7   0.750000\n",
              "regex_check_out        5      [1]     0.265  ...       53          0   1.000000\n",
              "short_comment          6      [0]     0.215  ...       32         11   0.744186\n",
              "has_person             7      [0]     0.075  ...       11          4   0.733333\n",
              "textblob_polarity      8      [0]     0.040  ...        7          1   0.875000\n",
              "textblob_subjectivity  9      [0]     0.350  ...       41         29   0.585714\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm1IyIa8bagC",
        "colab_type": "text"
      },
      "source": [
        "<h1>Now we will combine the outputs of all the labeling functions to get one label</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58h_30V3W9mp",
        "colab_type": "text"
      },
      "source": [
        "**Our goal is to convert the labels from our LFs into a single noise-aware probabilistic (or confidence-weighted) label per data point.<br>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8O8iMGLXDUb",
        "colab_type": "text"
      },
      "source": [
        "A simple baseline for doing this is to take the majority vote on a per-data point basis: if more LFs voted SPAM than HAM, label it SPAM (and vice versa)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJOw6D1DcCII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from snorkel.labeling import MajorityLabelVoter\n",
        "\n",
        "majority_model = MajorityLabelVoter()\n",
        "preds_train = majority_model.predict(L=L_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QxDhqn4VDDU",
        "colab_type": "code",
        "outputId": "8714b4fd-adf1-4515-f236-de159b2dc47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.unique(preds_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI4DxMmdcV75",
        "colab_type": "code",
        "outputId": "65e3e182-9758-4d87-b916-3b93e1aeb27f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5JCdcy1c0PS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we will use Snorkel's LabelModel to combine the outputs of the LFs.\n",
        "\n",
        "# This model will ultimately produce a single set of noise-aware training labels, \n",
        "# which are probabilistic or confidence-weighted labels. We will then use these labels to train a classifier for our task.\n",
        "\n",
        "# The LabelModel is able to learn weights for the labeling functions using only the label matrix as input.\n",
        "# no gold labels are used during the training process. They are just for evaluation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJEBg28Gd9Al",
        "colab_type": "code",
        "outputId": "bbf4abff-cf62-43b7-de5e-fef23e7143f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "L_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1, -1, -1, ..., -1, -1, -1],\n",
              "       [ 1,  1, -1, ..., -1, -1, -1],\n",
              "       [-1, -1, -1, ..., -1, -1, -1],\n",
              "       ...,\n",
              "       [-1,  1, -1, ..., -1, -1,  0],\n",
              "       [-1, -1, -1, ..., -1, -1,  0],\n",
              "       [-1, -1, -1, ..., -1,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByWoQwSmYgMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filtering non labelled points\n",
        "# L_temp = []\n",
        "# for l in L_train:\n",
        "#   if not all([True if pred == -1 else False for pred in l]):\n",
        "#     L_temp.append(l)\n",
        "# L_train = np.array(L_temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UrAW_59c4pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting the model on L_train(The matrix) and getting prediction for L_valid\n",
        "\n",
        "label_model = LabelModel(cardinality=2, verbose=True)  #cardinality - number of classes\n",
        "label_model.fit(L_train=L_train, n_epochs=1000, lr=0.001, log_freq=100, seed=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtDzDOmyeEAv",
        "colab_type": "code",
        "outputId": "761008a3-6c5b-49aa-90c3-172a06b3228c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#calculating score for majority model and snorkel's label_models\n",
        "majority_acc = majority_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
        "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
        "\n",
        "label_model_acc = label_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
        "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Majority Vote Accuracy:   84.3%\n",
            "Label Model Accuracy:     87.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjfUPLiBYJ4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_train = label_model.predict(L_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxELBbARYPJA",
        "colab_type": "code",
        "outputId": "e50b356f-802f-471a-cd36-8b14bc0db53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1380,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTpDCL_ofDQC",
        "colab_type": "code",
        "outputId": "06dde76d-8ce3-4972-f097-bd5461432f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#  This labeling is typically not suitable as an inference-time model to make predictions for unseen data points, \n",
        "#  due to (among other things) some data points having all abstain labels.\n",
        "\n",
        "#Now what we will do is this:\n",
        "#For every comment, we have a label either 0 or 1. Now instead of using this 0 and 1 to classify an unseen comment as SPAM or HAM \n",
        "#what we will do is supply this comment(X) and label(Y) to a discriminative classifier to see if we can improve performance further\n",
        "\n",
        "'''formaly'''\n",
        "#we will use the output of the label model as training labels to train a discriminative classifier.\n",
        "#This classifier will only need the text of the comment to make predictions, making it much more suitable for inference over unseen comments. "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'formaly'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWVCTHOzj6mh",
        "colab_type": "text"
      },
      "source": [
        "<h1>Filtering out unlabeled data points</h1>\n",
        "\n",
        "As we saw earlier, some of the data points in our train set received no labels from any of our LFs. \n",
        "These data points convey no supervision signal and tend to hurt performance, so we filter them out before training using a built-in utility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmUAXQEzqwM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from snorkel.labeling import filter_unlabeled_dataframe\n",
        "\n",
        "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
        "    X=df_train, y=preds_train, L=L_train\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTIPi8vmrOa4",
        "colab_type": "code",
        "outputId": "b6055f88-7eb3-4dc5-8b13-a42fc18006f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df_train_filtered)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dn3xiRTT1VN",
        "colab_type": "code",
        "outputId": "de2bc656-effe-419b-95a1-5b1e73873406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "probs_train_filtered[0:18]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N9-1gS7rtej",
        "colab_type": "text"
      },
      "source": [
        "<h1>Training a Classifier</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUabOtJErxyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we’ll use the noisy training labels to train a classifier for our task. \n",
        "# The output of the Snorkel LabelModel is just a set of labels which can be used with most popular libraries for performing supervised learning, \n",
        "# such as TensorFlow, Keras, PyTorch, Scikit-Learn, Ludwig, and XGBoost. \n",
        "# We will be using classifiers from Keras and Scikit-Learn."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dybztW-yr41O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Featurization\n",
        "\n",
        "# For simplicity and speed, we use a simple “bag of n-grams” feature representation: \n",
        "#each data point is represented by a one-hot vector marking which words or 2-word combinations are present in the comment text."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM9KPuXzsho7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "X_train = vectorizer.fit_transform(df_train_filtered.CONTENT.tolist())\n",
        "\n",
        "X_dev = vectorizer.transform(df_dev.CONTENT.tolist())\n",
        "X_valid = vectorizer.transform(df_valid.CONTENT.tolist())\n",
        "X_test = vectorizer.transform(df_test.CONTENT.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CUduC7rsyoT",
        "colab_type": "text"
      },
      "source": [
        "***Keras Classifier with Probabilistic Labels***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L423OWZys7IC",
        "colab_type": "code",
        "outputId": "a70586cb-5c47-4ec2-8e57-c2ffd52e8fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from snorkel.analysis import metric_score\n",
        "from snorkel.utils import preds_to_probs\n",
        "from utils import get_keras_logreg, get_keras_early_stopping\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Define a vanilla logistic regression model with Keras\n",
        "keras_model = get_keras_logreg(input_dim=X_train.shape[1])\n",
        "keras_model.fit(\n",
        "    x=X_train,\n",
        "    y=to_categorical(probs_train_filtered),\n",
        "    validation_data=(X_valid, to_categorical(Y_valid)),\n",
        "    callbacks=[get_keras_early_stopping()],\n",
        "    epochs=20,\n",
        "    verbose=0,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb93aa03128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMmhdQI_NUJh",
        "colab_type": "code",
        "outputId": "d7fa3208-935e-4c06-fabd-4dd6f995d4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds_test = keras_model.predict(x=X_test).argmax(axis=1)\n",
        "test_acc = metric_score(golds=Y_test, preds=preds_test, metric=\"accuracy\")\n",
        "print(f\"Test Accuracy: {test_acc * 100:.1f}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 88.1%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ9jsujAPB6n",
        "colab_type": "text"
      },
      "source": [
        "<h1>Summary</h1>\n",
        "In this tutorial, we accomplished the following:\n",
        "\n",
        "\n",
        "\n",
        "1.   We introduced the concept of Labeling Functions (LFs) and demonstrated some of the forms they can take.\n",
        "2.   We used the Snorkel LabelModel to automatically learn how to combine the outputs of our LFs into strong probabilistic labels.\n",
        "3.   We showed that a classifier trained on a weakly supervised dataset can outperform an approach based on the LFs alone as it learns to generalize beyond the noisy heuristics we provide."
      ]
    }
  ]
}