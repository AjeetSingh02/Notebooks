{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "resumeTrainingFromLastState_save_and_load.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjeetSingh02/Notebooks/blob/master/resumeTrainingFromLastState_save_and_load.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzIOVSdnMYyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795386f6-a8ca-4318-8f5d-78b37db9154a"
      },
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nm7Tyb-gRt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd51d35-4d4a-4fa3-bf8f-185f35904f48"
      },
      "source": [
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbGsznErXWt6"
      },
      "source": [
        "### Get an example dataset\n",
        "\n",
        "To demonstrate how to save and load weights, you'll use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). To speed up these runs, use the first 1000 examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rGfFwE9XVwz"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_labels = train_labels[:1000]\n",
        "test_labels = test_labels[:1000]\n",
        "\n",
        "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
        "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anG3iVoXyZGI"
      },
      "source": [
        "### Define a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wynsOBfby0Pa"
      },
      "source": [
        "Start by building a simple sequential model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HZbJIjxyX1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47693160-8420-4096-ce1b-5cb92e627a73"
      },
      "source": [
        "# Define a simple sequential model\n",
        "def create_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "\n",
        "# Display the model's architecture\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 407,050\n",
            "Trainable params: 407,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soDE0W_KH8rG"
      },
      "source": [
        "## Save checkpoints during training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRyd5qQQIXZm"
      },
      "source": [
        "You can use a trained model without having to retrain it, or pick-up training where you left off in case the training process was interrupted. The `tf.keras.callbacks.ModelCheckpoint` callback allows you to continually save the model both *during* and at *the end* of training.\n",
        "\n",
        "### Checkpoint callback usage\n",
        "\n",
        "Create a `tf.keras.callbacks.ModelCheckpoint` callback that saves weights only during training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFPuhwntH8VH"
      },
      "source": [
        "checkpoint_path = \"training_2/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxMdxzjUE62L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08214e9d-2e20-4433-f2e3-69c76da7fe51"
      },
      "source": [
        "# Train the model with the new callback\r\n",
        "model.fit(train_images, \r\n",
        "          train_labels,  \r\n",
        "          epochs=10,\r\n",
        "          validation_data=(test_images, test_labels),\r\n",
        "          callbacks=[cp_callback])  # Pass callback to training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 1.5810 - sparse_categorical_accuracy: 0.4919 - val_loss: 0.7508 - val_sparse_categorical_accuracy: 0.7750\n",
            "\n",
            "Epoch 00001: saving model to training_2/cp.ckpt\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.4654 - sparse_categorical_accuracy: 0.8779 - val_loss: 0.5412 - val_sparse_categorical_accuracy: 0.8320\n",
            "\n",
            "Epoch 00002: saving model to training_2/cp.ckpt\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.3153 - sparse_categorical_accuracy: 0.9293 - val_loss: 0.4669 - val_sparse_categorical_accuracy: 0.8560\n",
            "\n",
            "Epoch 00003: saving model to training_2/cp.ckpt\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2225 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.4374 - val_sparse_categorical_accuracy: 0.8620\n",
            "\n",
            "Epoch 00004: saving model to training_2/cp.ckpt\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1853 - sparse_categorical_accuracy: 0.9574 - val_loss: 0.4406 - val_sparse_categorical_accuracy: 0.8500\n",
            "\n",
            "Epoch 00005: saving model to training_2/cp.ckpt\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1374 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.4398 - val_sparse_categorical_accuracy: 0.8580\n",
            "\n",
            "Epoch 00006: saving model to training_2/cp.ckpt\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0941 - sparse_categorical_accuracy: 0.9836 - val_loss: 0.4305 - val_sparse_categorical_accuracy: 0.8630\n",
            "\n",
            "Epoch 00007: saving model to training_2/cp.ckpt\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0768 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.4497 - val_sparse_categorical_accuracy: 0.8440\n",
            "\n",
            "Epoch 00008: saving model to training_2/cp.ckpt\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0564 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.4170 - val_sparse_categorical_accuracy: 0.8660\n",
            "\n",
            "Epoch 00009: saving model to training_2/cp.ckpt\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0358 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4294 - val_sparse_categorical_accuracy: 0.8660\n",
            "\n",
            "Epoch 00010: saving model to training_2/cp.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb4e7938510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D462WobmfVLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "353f13c3-44e8-45ca-e4d7-28f756ebebce"
      },
      "source": [
        "# Train the model with the new callback\r\n",
        "model.fit(train_images, \r\n",
        "          train_labels,  \r\n",
        "          epochs=10,\r\n",
        "          validation_data=(test_images, test_labels),\r\n",
        "          callbacks=[cp_callback])  # Pass callback to training"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0285 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4018 - val_sparse_categorical_accuracy: 0.8710\n",
            "\n",
            "Epoch 00001: saving model to training_1/cp.ckpt\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0282 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4076 - val_sparse_categorical_accuracy: 0.8720\n",
            "\n",
            "Epoch 00002: saving model to training_1/cp.ckpt\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0206 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4239 - val_sparse_categorical_accuracy: 0.8740\n",
            "\n",
            "Epoch 00003: saving model to training_1/cp.ckpt\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0155 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4155 - val_sparse_categorical_accuracy: 0.8770\n",
            "\n",
            "Epoch 00004: saving model to training_1/cp.ckpt\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0154 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.4054 - val_sparse_categorical_accuracy: 0.8780\n",
            "\n",
            "Epoch 00005: saving model to training_1/cp.ckpt\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0126 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4157 - val_sparse_categorical_accuracy: 0.8720\n",
            "\n",
            "Epoch 00006: saving model to training_1/cp.ckpt\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0117 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4204 - val_sparse_categorical_accuracy: 0.8770\n",
            "\n",
            "Epoch 00007: saving model to training_1/cp.ckpt\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0088 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4302 - val_sparse_categorical_accuracy: 0.8740\n",
            "\n",
            "Epoch 00008: saving model to training_1/cp.ckpt\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0081 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4184 - val_sparse_categorical_accuracy: 0.8770\n",
            "\n",
            "Epoch 00009: saving model to training_1/cp.ckpt\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0080 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4296 - val_sparse_categorical_accuracy: 0.8780\n",
            "\n",
            "Epoch 00010: saving model to training_1/cp.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f57f89ee5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlM-sgyJO084"
      },
      "source": [
        "This creates a single collection of TensorFlow checkpoint files that are updated at the end of each epoch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXG5FVKFOVQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db31974c-1802-4b6f-89fc-a29bea3c5a0e"
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint  cp.ckpt.data-00000-of-00001  cp.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlRN_f56Pqa9"
      },
      "source": [
        "As long as two models share the same architecture you can share weights between them. So, when restoring a model from weights-only, create a model with the same architecture as the original model and then set its weights. \n",
        "\n",
        "Now rebuild a fresh, untrained model and evaluate it on the test set. An untrained model will perform at chance levels (~10% accuracy):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp5gbuiaPqCT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb9e2221-eef0-4e7d-ccfc-b8dfeaabb1b9"
      },
      "source": [
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 2.3406 - sparse_categorical_accuracy: 0.1040\n",
            "Untrained model, accuracy: 10.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DTKpZssRSo3"
      },
      "source": [
        "Then load the weights from the checkpoint and re-evaluate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IZxbwiRRSD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "073702da-aa40-42d7-e6b0-6262a85a8d68"
      },
      "source": [
        "# Loads the weights\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.4795 - sparse_categorical_accuracy: 0.8800\n",
            "Restored model, accuracy: 88.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpAbKkAyVPV8"
      },
      "source": [
        "### Checkpoint callback options\n",
        "\n",
        "The callback provides several options to provide unique names for checkpoints and adjust the checkpointing frequency.\n",
        "\n",
        "Train a new model, and save uniquely named checkpoints once every five epochs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQF_dlgIVOvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8c69f6-1032-4909-9177-f7cf02a0656f"
      },
      "source": [
        "# Include the epoch in the file name (uses `str.format`)\n",
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=5*batch_size)\n",
        "\n",
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(train_images, \n",
        "          train_labels,\n",
        "          epochs=50, \n",
        "          callbacks=[cp_callback],\n",
        "          validation_data=(test_images, test_labels),\n",
        "          verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "\n",
            "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
            "\n",
            "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
            "\n",
            "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
            "\n",
            "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
            "\n",
            "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
            "\n",
            "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
            "\n",
            "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
            "\n",
            "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
            "\n",
            "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
            "\n",
            "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f03c00e35d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zFrKTjjavWI"
      },
      "source": [
        "Now, look at the resulting checkpoints and choose the latest one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p64q3-V4sXt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "419280ac-f9c8-4501-a619-5a508a10e440"
      },
      "source": [
        "!ls {checkpoint_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t  cp-0025.ckpt.index\n",
            "cp-0000.ckpt.data-00000-of-00001  cp-0030.ckpt.data-00000-of-00001\n",
            "cp-0000.ckpt.index\t\t  cp-0030.ckpt.index\n",
            "cp-0005.ckpt.data-00000-of-00001  cp-0035.ckpt.data-00000-of-00001\n",
            "cp-0005.ckpt.index\t\t  cp-0035.ckpt.index\n",
            "cp-0010.ckpt.data-00000-of-00001  cp-0040.ckpt.data-00000-of-00001\n",
            "cp-0010.ckpt.index\t\t  cp-0040.ckpt.index\n",
            "cp-0015.ckpt.data-00000-of-00001  cp-0045.ckpt.data-00000-of-00001\n",
            "cp-0015.ckpt.index\t\t  cp-0045.ckpt.index\n",
            "cp-0020.ckpt.data-00000-of-00001  cp-0050.ckpt.data-00000-of-00001\n",
            "cp-0020.ckpt.index\t\t  cp-0050.ckpt.index\n",
            "cp-0025.ckpt.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AN_fnuyR41H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "49313ea5-cbfc-4558-fb6d-1256f9f8de8a"
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'training_2/cp-0050.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk2ciGbKg561"
      },
      "source": [
        "Note: the default TensorFlow format only saves the 5 most recent checkpoints.\n",
        "\n",
        "To test, reset the model and load the latest checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M04jyK-H3QK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779f5b99-e602-4915-aaad-939034fe42ef"
      },
      "source": [
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Load the previously saved weights\n",
        "model.load_weights(latest)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 - 0s - loss: 0.5011 - sparse_categorical_accuracy: 0.8730\n",
            "Restored model, accuracy: 87.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsdTsS26eVsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b192a068-c7b0-48f8-e8e4-a468e6015867"
      },
      "source": [
        "import numpy as np\r\n",
        "from numpy.testing import assert_allclose\r\n",
        "from tensorflow.keras.models import Sequential, load_model\r\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "\r\n",
        "vec_size = 100\r\n",
        "n_units = 10\r\n",
        "\r\n",
        "x_train = np.random.rand(500, 10, vec_size)\r\n",
        "y_train = np.random.rand(500, vec_size)\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(LSTM(n_units, input_shape=(None, vec_size), return_sequences=True))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(LSTM(n_units, return_sequences=True))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(LSTM(n_units))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(vec_size, activation='linear'))\r\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\r\n",
        "\r\n",
        "# define the checkpoint\r\n",
        "filepath = \"model.h5\"\r\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\r\n",
        "callbacks_list = [checkpoint]\r\n",
        "\r\n",
        "# fit the model\r\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=50, callbacks=callbacks_list)\r\n",
        "\r\n",
        "# load the model\r\n",
        "new_model = load_model(\"model.h5\")\r\n",
        "assert_allclose(model.predict(x_train),\r\n",
        "                new_model.predict(x_train),\r\n",
        "                1e-5)\r\n",
        "\r\n",
        "# fit the model\r\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\r\n",
        "callbacks_list = [checkpoint]\r\n",
        "new_model.fit(x_train, y_train, epochs=5, batch_size=50, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10/10 [==============================] - 31s 5ms/step - loss: 0.3237\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.31665, saving model to model.h5\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2894\n",
            "\n",
            "Epoch 00002: loss improved from 0.31665 to 0.28459, saving model to model.h5\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2534\n",
            "\n",
            "Epoch 00003: loss improved from 0.28459 to 0.24435, saving model to model.h5\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2084\n",
            "\n",
            "Epoch 00004: loss improved from 0.24435 to 0.19932, saving model to model.h5\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1679\n",
            "\n",
            "Epoch 00005: loss improved from 0.19932 to 0.16083, saving model to model.h5\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 1s 5ms/step - loss: 0.1346\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.13465, saving model to model.h5\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1214\n",
            "\n",
            "Epoch 00002: loss improved from 0.13465 to 0.12140, saving model to model.h5\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1131\n",
            "\n",
            "Epoch 00003: loss improved from 0.12140 to 0.11312, saving model to model.h5\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1068\n",
            "\n",
            "Epoch 00004: loss improved from 0.11312 to 0.10683, saving model to model.h5\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.1039\n",
            "\n",
            "Epoch 00005: loss improved from 0.10683 to 0.10392, saving model to model.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f61712f9d10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}