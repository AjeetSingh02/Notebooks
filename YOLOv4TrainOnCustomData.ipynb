{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv4-Darknet-Roboflow-Experiments.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjeetSingh02/Notebooks/blob/master/YOLOv4TrainOnCustomData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKdcMGDjF5nv"
      },
      "source": [
        "Original Source\n",
        "\n",
        "https://colab.research.google.com/drive/1mzL6WyY9BRx4xX476eQdhKDnd_eixBlG#scrollTo=GNVU7eu9CQj3\n",
        "\n",
        "https://blog.roboflow.com/training-yolov4-on-a-custom-dataset/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNVU7eu9CQj3"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "In this notebook, we implement [YOLOv4](https://arxiv.org/pdf/2004.10934.pdf) for training on your own dataset.\n",
        "\n",
        "We also recommend reading our blog post on [Training YOLOv4 on custom data](https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/) side by side.\n",
        "\n",
        "We will take the following steps to implement YOLOv4 on our custom data:\n",
        "* Configure our GPU environment on Google Colab\n",
        "* Install the Darknet YOLOv4 training environment\n",
        "* Download our custom dataset for YOLOv4 and set up directories\n",
        "* Configure a custom YOLOv4 training config file for Darknet\n",
        "* Train our custom YOLOv4 object detector\n",
        "* Reload YOLOv4 trained weights and make inference on test images\n",
        "\n",
        "When you are done you will have a custom detector that you can use. It will make inference like this:\n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/L0n564N.png)\n",
        "\n",
        "### **Reach out for support**\n",
        "\n",
        "If you run into any hurdles on your own data set or just want to share some cool results in your own domain, [reach out!](https://roboflow.ai) \n",
        "\n",
        "\n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDTvGt2zt7cm"
      },
      "source": [
        "# Configuring cuDNN on Colab for YOLOv4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-bguKWgtxSx"
      },
      "source": [
        "# CUDA: Let's check that Nvidia CUDA drivers are already pre-installed and which version is it.\n",
        "!/usr/local/cuda/bin/nvcc --version\n",
        "# We need to install the correct cuDNN according to this output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJYM7-_Had0Q"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_qFPIBgvlkn"
      },
      "source": [
        "# This cell ensures you have the correct architecture for your respective GPU\n",
        "# If you command is not found, look through these GPUs, find the respective\n",
        "# GPU and add them to the archTypes dictionary\n",
        "\n",
        "# Tesla V100\n",
        "# ARCH= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
        "\n",
        "# Tesla K80 \n",
        "# ARCH= -gencode arch=compute_37,code=sm_37\n",
        "\n",
        "# GeForce RTX 2080 Ti, RTX 2080, RTX 2070, Quadro RTX 8000, Quadro RTX 6000, Quadro RTX 5000, Tesla T4, XNOR Tensor Cores\n",
        "# ARCH= -gencode arch=compute_75,code=[sm_75,compute_75]\n",
        "\n",
        "# Jetson XAVIER\n",
        "# ARCH= -gencode arch=compute_72,code=[sm_72,compute_72]\n",
        "\n",
        "# GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4\n",
        "# ARCH= -gencode arch=compute_61,code=sm_61\n",
        "\n",
        "# GP100/Tesla P100 - DGX-1\n",
        "# ARCH= -gencode arch=compute_60,code=sm_60\n",
        "\n",
        "# For Jetson TX1, Tegra X1, DRIVE CX, DRIVE PX - uncomment:\n",
        "# ARCH= -gencode arch=compute_53,code=[sm_53,compute_53]\n",
        "\n",
        "# For Jetson Tx2 or Drive-PX2 uncomment:\n",
        "# ARCH= -gencode arch=compute_62,code=[sm_62,compute_62]\n",
        "import os\n",
        "os.environ['GPU_TYPE'] = str(os.popen('nvidia-smi --query-gpu=name --format=csv,noheader').read())\n",
        "\n",
        "def getGPUArch(argument):\n",
        "  try:\n",
        "    argument = argument.strip()\n",
        "    # All Colab GPUs\n",
        "    archTypes = {\n",
        "        \"Tesla V100-SXM2-16GB\": \"-gencode arch=compute_70,code=[sm_70,compute_70]\",\n",
        "        \"Tesla K80\": \"-gencode arch=compute_37,code=sm_37\",\n",
        "        \"Tesla T4\": \"-gencode arch=compute_75,code=[sm_75,compute_75]\",\n",
        "        \"Tesla P40\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "        \"Tesla P4\": \"-gencode arch=compute_61,code=sm_61\",\n",
        "        \"Tesla P100-PCIE-16GB\": \"-gencode arch=compute_60,code=sm_60\"\n",
        "\n",
        "      }\n",
        "    return archTypes[argument]\n",
        "  except KeyError:\n",
        "    return \"GPU must be added to GPU Commands\"\n",
        "os.environ['ARCH_VALUE'] = getGPUArch(os.environ['GPU_TYPE'])\n",
        "\n",
        "print(\"GPU Type: \" + os.environ['GPU_TYPE'])\n",
        "print(\"ARCH Value: \" + os.environ['ARCH_VALUE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3nkYzWwMuBk"
      },
      "source": [
        "## STEP 1. Install cuDNN according to the current CUDA version\n",
        "Colab added cuDNN as an inherent install - so you don't have to do a thing - major win\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16pvdFMa1FEe"
      },
      "source": [
        "# Step 2: Installing Darknet for YOLOv4 on Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVEHA_5bFfkG"
      },
      "source": [
        "# go into the contect directory\n",
        "%cd /content/\n",
        "\n",
        "# Remove the listed directories and their contents recursively \n",
        "# force the rm command to ignore nonexistent files and missing operands, and never prompt the user\n",
        "%rm -rf darknet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLKkz82BkPjv"
      },
      "source": [
        "Next, we clone our fork of the Darknet YOLO v4 repository. We have made a few minor tweaks to remove print statements and to change the Makefile to play well with Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQEktcfj9y9O"
      },
      "source": [
        "# we clone the fork of darknet maintained by roboflow\n",
        "# small changes have been made to configure darknet for training\n",
        "!git clone https://github.com/roboflow-ai/darknet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O6dTiq5ga0I"
      },
      "source": [
        "# Go into /content/darknet/ and delete the existing makefile\n",
        "%cd /content/darknet/\n",
        "%rm Makefile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyTAyEhOgd__"
      },
      "source": [
        "# colab occasionally shifts dependencies around, \n",
        "# at the time of authorship, this Makefile works for building Darknet on Colab\n",
        "\n",
        "%%writefile Makefile\n",
        "GPU=1\n",
        "CUDNN=1\n",
        "CUDNN_HALF=0\n",
        "OPENCV=1\n",
        "AVX=0\n",
        "OPENMP=0\n",
        "LIBSO=1\n",
        "ZED_CAMERA=0\n",
        "ZED_CAMERA_v2_8=0\n",
        "\n",
        "# set GPU=1 and CUDNN=1 to speedup on GPU\n",
        "# set CUDNN_HALF=1 to further speedup 3 x times (Mixed-precision on Tensor Cores) \n",
        "# [continue from above line] GPU: Volta, Xavier, Turing and higher\n",
        "# set AVX=1 and OPENMP=1 to speedup on CPU (if error occurs then set AVX=0)\n",
        "# set ZED_CAMERA=1 to enable ZED SDK 3.0 and above\n",
        "# set ZED_CAMERA_v2_8=1 to enable ZED SDK 2.X\n",
        "\n",
        "USE_CPP=0\n",
        "DEBUG=0\n",
        "\n",
        "ARCH= -gencode arch=compute_35,code=sm_35 \\\n",
        "      -gencode arch=compute_50,code=[sm_50,compute_50] \\\n",
        "      -gencode arch=compute_52,code=[sm_52,compute_52] \\\n",
        "\t    -gencode arch=compute_61,code=[sm_61,compute_61] \\\n",
        "      -gencode arch=compute_37,code=sm_37\n",
        "\n",
        "ARCH= -gencode arch=compute_60,code=sm_60\n",
        "\n",
        "OS := $(shell uname)\n",
        "\n",
        "VPATH=./src/\n",
        "EXEC=darknet\n",
        "OBJDIR=./obj/\n",
        "\n",
        "ifeq ($(LIBSO), 1)\n",
        "LIBNAMESO=libdarknet.so\n",
        "APPNAMESO=uselib\n",
        "endif\n",
        "\n",
        "ifeq ($(USE_CPP), 1)\n",
        "CC=g++\n",
        "else\n",
        "CC=gcc\n",
        "endif\n",
        "\n",
        "CPP=g++ -std=c++11\n",
        "NVCC=nvcc\n",
        "OPTS=-Ofast\n",
        "LDFLAGS= -lm -pthread\n",
        "COMMON= -Iinclude/ -I3rdparty/stb/include\n",
        "CFLAGS=-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC\n",
        "\n",
        "ifeq ($(DEBUG), 1)\n",
        "#OPTS= -O0 -g\n",
        "#OPTS= -Og -g\n",
        "COMMON+= -DDEBUG\n",
        "CFLAGS+= -DDEBUG\n",
        "else\n",
        "ifeq ($(AVX), 1)\n",
        "CFLAGS+= -ffp-contract=fast -mavx -mavx2 -msse3 -msse4.1 -msse4.2 -msse4a\n",
        "endif\n",
        "endif\n",
        "\n",
        "CFLAGS+=$(OPTS)\n",
        "\n",
        "ifneq (,$(findstring MSYS_NT,$(OS)))\n",
        "LDFLAGS+=-lws2_32\n",
        "endif\n",
        "\n",
        "ifeq ($(OPENCV), 1)\n",
        "COMMON+= -DOPENCV\n",
        "CFLAGS+= -DOPENCV\n",
        "LDFLAGS+= `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv`\n",
        "COMMON+= `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv`\n",
        "endif\n",
        "\n",
        "ifeq ($(OPENMP), 1)\n",
        "CFLAGS+= -fopenmp\n",
        "LDFLAGS+= -lgomp\n",
        "endif\n",
        "\n",
        "ifeq ($(GPU), 1)\n",
        "COMMON+= -DGPU -I/usr/local/cuda/include/\n",
        "CFLAGS+= -DGPU\n",
        "ifeq ($(OS),Darwin) #MAC\n",
        "LDFLAGS+= -L/usr/local/cuda/lib -lcuda -lcudart -lcublas -lcurand\n",
        "else\n",
        "LDFLAGS+= -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand\n",
        "endif\n",
        "endif\n",
        "\n",
        "ifeq ($(CUDNN), 1)\n",
        "COMMON+= -DCUDNN\n",
        "ifeq ($(OS),Darwin) #MAC\n",
        "CFLAGS+= -DCUDNN -I/usr/local/cuda/include\n",
        "LDFLAGS+= -L/usr/local/cuda/lib -lcudnn\n",
        "else\n",
        "CFLAGS+= -DCUDNN -I/usr/local/cudnn/include\n",
        "LDFLAGS+= -L/usr/local/cudnn/lib64 -lcudnn\n",
        "endif\n",
        "endif\n",
        "\n",
        "ifeq ($(CUDNN_HALF), 1)\n",
        "COMMON+= -DCUDNN_HALF\n",
        "CFLAGS+= -DCUDNN_HALF\n",
        "ARCH+= -gencode arch=compute_70,code=[sm_70,compute_70]\n",
        "endif\n",
        "\n",
        "ifeq ($(ZED_CAMERA), 1)\n",
        "CFLAGS+= -DZED_STEREO -I/usr/local/zed/include\n",
        "ifeq ($(ZED_CAMERA_v2_8), 1)\n",
        "LDFLAGS+= -L/usr/local/zed/lib -lsl_core -lsl_input -lsl_zed\n",
        "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\n",
        "else\n",
        "LDFLAGS+= -L/usr/local/zed/lib -lsl_zed\n",
        "#-lstdc++ -D_GLIBCXX_USE_CXX11_ABI=0\n",
        "endif\n",
        "endif\n",
        "\n",
        "OBJ=image_opencv.o http_stream.o gemm.o utils.o dark_cuda.o convolutional_layer.o list.o image.o activations.o im2col.o col2im.o blas.o crop_layer.o dropout_layer.o maxpool_layer.o softmax_layer.o data.o matrix.o network.o connected_layer.o cost_layer.o parser.o option_list.o darknet.o detection_layer.o captcha.o route_layer.o writing.o box.o nightmare.o normalization_layer.o avgpool_layer.o coco.o dice.o yolo.o detector.o layer.o compare.o classifier.o local_layer.o swag.o shortcut_layer.o activation_layer.o rnn_layer.o gru_layer.o rnn.o rnn_vid.o crnn_layer.o demo.o tag.o cifar.o go.o batchnorm_layer.o art.o region_layer.o reorg_layer.o reorg_old_layer.o super.o voxel.o tree.o yolo_layer.o gaussian_yolo_layer.o upsample_layer.o lstm_layer.o conv_lstm_layer.o scale_channels_layer.o sam_layer.o\n",
        "ifeq ($(GPU), 1)\n",
        "LDFLAGS+= -lstdc++\n",
        "OBJ+=convolutional_kernels.o activation_kernels.o im2col_kernels.o col2im_kernels.o blas_kernels.o crop_layer_kernels.o dropout_layer_kernels.o maxpool_layer_kernels.o network_kernels.o avgpool_layer_kernels.o\n",
        "endif\n",
        "\n",
        "OBJS = $(addprefix $(OBJDIR), $(OBJ))\n",
        "DEPS = $(wildcard src/*.h) Makefile include/darknet.h\n",
        "\n",
        "all: $(OBJDIR) backup results setchmod $(EXEC) $(LIBNAMESO) $(APPNAMESO)\n",
        "\n",
        "ifeq ($(LIBSO), 1)\n",
        "CFLAGS+= -fPIC\n",
        "\n",
        "$(LIBNAMESO): $(OBJDIR) $(OBJS) include/yolo_v2_class.hpp src/yolo_v2_class.cpp\n",
        "\t$(CPP) -shared -std=c++11 -fvisibility=hidden -DLIB_EXPORTS $(COMMON) $(CFLAGS) $(OBJS) src/yolo_v2_class.cpp -o $@ $(LDFLAGS)\n",
        "\n",
        "$(APPNAMESO): $(LIBNAMESO) include/yolo_v2_class.hpp src/yolo_console_dll.cpp\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -o $@ src/yolo_console_dll.cpp $(LDFLAGS) -L ./ -l:$(LIBNAMESO)\n",
        "endif\n",
        "\n",
        "$(EXEC): $(OBJS)\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) $^ -o $@ $(LDFLAGS)\n",
        "\n",
        "$(OBJDIR)%.o: %.c $(DEPS)\n",
        "\t$(CC) $(COMMON) $(CFLAGS) -c $< -o $@\n",
        "\n",
        "$(OBJDIR)%.o: %.cpp $(DEPS)\n",
        "\t$(CPP) -std=c++11 $(COMMON) $(CFLAGS) -c $< -o $@\n",
        "\n",
        "$(OBJDIR)%.o: %.cu $(DEPS)\n",
        "\t$(NVCC) $(ARCH) $(COMMON) --compiler-options \"$(CFLAGS)\" -c $< -o $@\n",
        "\n",
        "$(OBJDIR):\n",
        "\tmkdir -p $(OBJDIR)\n",
        "backup:\n",
        "\tmkdir -p backup\n",
        "results:\n",
        "\tmkdir -p results\n",
        "setchmod:\n",
        "\tchmod +x *.sh\n",
        "\n",
        ".PHONY: clean\n",
        "\n",
        "clean:\n",
        "\trm -rf $(OBJS) $(EXEC) $(LIBNAMESO) $(APPNAMESO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZJNs11CKgVw"
      },
      "source": [
        "'''Small Piece of lines from makefile'''\n",
        "# ARCH= -gencode arch=compute_35,code=sm_35 \\\n",
        "#       -gencode arch=compute_50,code=[sm_50,compute_50] \\\n",
        "#       -gencode arch=compute_52,code=[sm_52,compute_52] \\\n",
        "# \t    -gencode arch=compute_61,code=[sm_61,compute_61] \\\n",
        "#       -gencode arch=compute_37,code=sm_37\n",
        "\n",
        "# ARCH= -gencode arch=compute_60,code=sm_60"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5NaZ7BiKnV7"
      },
      "source": [
        "'''Colab GPU architecture'''\n",
        "# GPU Type: Tesla K80\n",
        "# ARCH Value: -gencode arch=compute_37,code=sm_37"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFtyN_hXLF0t"
      },
      "source": [
        "os.environ['ARCH_VALUE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7Gxw5U1L5F-"
      },
      "source": [
        "# This cell shows example of makefile editing used in the next code cell\n",
        "# Example of changing makefile configurations\n",
        "'''\n",
        "FORMAT:\n",
        "!sed -i 's/<field name>=<existing value>/<field name>=<new value>/g' <fileName>\n",
        "\n",
        "EXAMPLE\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qa9BMDbk7Sm"
      },
      "source": [
        "Moving along, after we have clone the repository and made a makefile, we !make (install/build) Darknet for YOLOv4. If your make is successful, you will see a number of printouts and at the bottom you will see the line beginning with:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV pkg-config --cflags opencv4 2> /dev/null\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2PsyHwjveWF"
      },
      "source": [
        "**Install/Build/Make Darknet for YOLO V4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyMBDkaL-Aep"
      },
      "source": [
        "# install environment from the Makefile\n",
        "# note if you are on Colab Pro this works on a P100 GPU\n",
        "# if you are on Colab free, you may need to change the Makefile for the K80 GPU\n",
        "# this goes for any GPU, you need to change the Makefile to inform darknet which GPU you are running on.\n",
        "# note the Makefile above should work for you, if you need to tweak, try the below\n",
        "%cd /content/darknet/\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/g' Makefile\n",
        "!sed -i 's/GPU=0/GPU=1/g' Makefile\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/g' Makefile\n",
        "!sed -i \"s/ARCH= -gencode arch=compute_60,code=sm_60/ARCH= ${ARCH_VALUE}/g\" Makefile\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDFawIgHl8Ks"
      },
      "source": [
        "Finally, we download the newly released convolutional neural network weights used in YOLOv4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGPDEjfAALrQ"
      },
      "source": [
        "#download the newly released yolov4 ConvNet weights\n",
        "%cd /content/darknet\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWOiKj37l4wW"
      },
      "source": [
        "# Set up Custom Dataset for YOLOv4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbniFj-eSimL"
      },
      "source": [
        "We'll use Roboflow to convert our dataset from any format to the YOLO Darknet format. \n",
        "\n",
        "1. To do so, create a free [Roboflow account](https://app.roboflow.ai).\n",
        "2. Upload your images and their annotations (in any format: VOC XML, COCO JSON, TensorFlow CSV, etc).\n",
        "3. Apply preprocessing and augmentation steps you may like. We recommend at least `auto-orient` and a `resize` to 416x416. Generate your dataset.\n",
        "4. Export your dataset in the **YOLO Darknet format**.\n",
        "5. Copy your download link, and paste it below.\n",
        "\n",
        "See our [blog post](https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/) for greater detail.\n",
        "\n",
        "In this example, I used the open source [BCCD Dataset](https://public.roboflow.ai/object-detection/bccd). (You can `fork` it to your Roboflow account to follow along.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdj4tmT5Cmdl"
      },
      "source": [
        "#if you already have YOLO darknet format, you can skip this step\n",
        "# To get the dummy dataset link, if on colab, use the blog post's method\n",
        "# of using ROBOFLOW mentioned above\n",
        "\n",
        "%cd /content/darknet\n",
        "!curl -L \"https://app.roboflow.com/ds/ogYkHHAoji?key=RJYctu9CSS\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKJNtEx0nPRZ"
      },
      "source": [
        "If you are on local, and already have your dataset in the right format, you can use the same Roboflow link or simply copy your files into the directories manually.\n",
        "\n",
        "Here on Colab, we will run some code to move the image and annotation files into the correct directories for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ie7y8TTn02D"
      },
      "source": [
        "# All the files will be downloaded and  unzipped inside \"darknet\" directory.\n",
        "!ls /content/darknet/train/ | tail -n 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW0W7gOZpCV6"
      },
      "source": [
        "!ls /content/darknet/data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1etsEOqwsiCI"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiCILEbs1NII"
      },
      "source": [
        "#Set up training file directories for custom dataset\n",
        "%cd /content/darknet/\n",
        "\n",
        "# copy darkent.labels into obj.names inside \"data\" directory\n",
        "%cp train/_darknet.labels data/obj.names\n",
        "\n",
        "# create new directory data/obj/\n",
        "%mkdir data/obj\n",
        "\n",
        "#copy images into newly created directory data/obj/\n",
        "%cp train/*.jpg data/obj/\n",
        "%cp valid/*.jpg data/obj/\n",
        "\n",
        "# copy labels into newly created directory data/obj/\n",
        "%cp train/*.txt data/obj/\n",
        "%cp valid/*.txt data/obj/\n",
        "\n",
        "# creating obj.data file inside \"data\" directory\n",
        "with open('data/obj.data', 'w') as out:\n",
        "  out.write('classes = 3\\n')\n",
        "  out.write('train = data/train.txt\\n')\n",
        "  out.write('valid = data/valid.txt\\n')\n",
        "  out.write('names = data/obj.names\\n')\n",
        "  out.write('backup = backup/')\n",
        "\n",
        "# write train file (just the image list). Paths of all the train images \n",
        "# will be written in data/train.txt\n",
        "with open('data/train.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir('train') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')\n",
        "\n",
        "# write the valid file (just the image list). Paths of all the validation images \n",
        "# will be written in data/valid.txt\n",
        "with open('data/valid.txt', 'w') as out:\n",
        "  for img in [f for f in os.listdir('valid') if f.endswith('jpg')]:\n",
        "    out.write('data/obj/' + img + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv0K0-VHtPeX"
      },
      "source": [
        "**State of files after above step should be something like this**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9YPhLqltWet"
      },
      "source": [
        "FILE: **obj.names**\n",
        "\n",
        "```\n",
        "Platelets\n",
        "RBC\n",
        "WBC\n",
        "```\n",
        "\n",
        "FILE: **obj.data**\n",
        "\n",
        "```\n",
        "classes = 3\n",
        "train = data/train.txt\n",
        "valid = data/valid.txt\n",
        "names = data/obj.names\n",
        "backup = backup/\n",
        "```\n",
        "\n",
        "FILE: **train.txt**\n",
        "\n",
        "```\n",
        "data/obj/BloodImage_00142_jpg.rf.2efb704d00cfc1dc45cf1d1843b35322.jpg\n",
        "data/obj/BloodImage_00172_jpg.rf.8d14b233517aec0256a70e7f5e48c244.jpg\n",
        "data/obj/BloodImage_00156_jpg.rf.2d6a939d6d60907251e8861900c06938.jpg\n",
        "data/obj/BloodImage_00365_jpg.rf.9162e7f6975aaa87da51862a529ab47d.jpg\n",
        "...\n",
        "```\n",
        "\n",
        "\n",
        "FILE: **valid.txt**\n",
        "\n",
        "```\n",
        "data/obj/BloodImage_00296_jpg.rf.4124ab3ce7e7fd64565b8893f1b61952.jpg\n",
        "data/obj/BloodImage_00272_jpg.rf.8f6d503984f06fee468bd10e597825c0.jpg\n",
        "data/obj/BloodImage_00281_jpg.rf.c096b46e2a4e1123a1d0bad0cfd22660.jpg\n",
        "data/obj/BloodImage_00403_jpg.rf.8efa0212d63452ff224e264ead3a8f3d.jpg\n",
        "...\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XtRCbICtMX4"
      },
      "source": [
        "!ls /content/darknet/data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkbuePIruyoV"
      },
      "source": [
        "!ls /content/darknet/data/obj | tail -n 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HtRqO3QvjkP"
      },
      "source": [
        "# Write Custom Training Config for YOLOv4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRTAS0wAz2QM"
      },
      "source": [
        "Configuring the training config for YOLOv4 for a custom dataset is tricky, and we handle it automatically for you in this tutorial. \n",
        "\n",
        "We'll set defaults for the learning rate and batch size below, and you should feel free to adjust these to your dataset's needs. We set up the config by combining a series of chunked config files. We take the following steps according to the YOLOv4 repository:\n",
        "\n",
        "\n",
        "1.   Set batch size to 64 - batch size is the number of images per iteration\n",
        "2.   Set subdivisions to 12 - subdivisions are the number of pieces your batch is broken into for GPU memory.\n",
        "3.   Set max_batches to 2000 * number of classes\n",
        "4.   Set steps to 80% and 90% of max batches\n",
        "5.   Change num_classes in all of the YOLO layers\n",
        "6.   Change filters in all of the YOLO layers\n",
        "\n",
        "Most of these you will not need to change. You may want to change the subdivision size to speed up training (smaller subdivisions are faster) or if your GPU does not have enough memory (larger subdivisions require less memory)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_WJcqHhpeVr"
      },
      "source": [
        "# we build config dynamically based on number of classes\n",
        "# we build iteratively from base config files. This is the same file shape as cfg/yolo-obj.cfg\n",
        "def file_len(fname):\n",
        "  with open(fname) as f:\n",
        "    for i, l in enumerate(f):\n",
        "      pass\n",
        "  return i + 1\n",
        "\n",
        "num_classes = file_len('train/_darknet.labels')\n",
        "print(\"writing config for a custom YOLOv4 detector detecting number of classes: \" + str(num_classes))\n",
        "\n",
        "#Instructions from the darknet repo\n",
        "#change line max_batches to (classes*2000 but not less than number of \n",
        "# training images, and not less than 6000), i.e. max_batches=6000 if you train for 3 classes\n",
        "#change line steps to 80% and 90% of max_batches, i.e. steps=4800,5400\n",
        "if os.path.exists('./cfg/custom-yolov4-detector.cfg'): os.remove('./cfg/custom-yolov4-detector.cfg')\n",
        "\n",
        "\n",
        "with open('./cfg/custom-yolov4-detector.cfg', 'a') as f:\n",
        "  f.write('[net]' + '\\n')\n",
        "  f.write('batch=64' + '\\n')\n",
        "  #####smaller subdivisions help the GPU run faster. 12 is optimal, but you might need to change to 24,36,64####\n",
        "  f.write('subdivisions=24' + '\\n')\n",
        "  f.write('width=416' + '\\n')\n",
        "  f.write('height=416' + '\\n')\n",
        "  f.write('channels=3' + '\\n')\n",
        "  f.write('momentum=0.949' + '\\n')\n",
        "  f.write('decay=0.0005' + '\\n')\n",
        "  f.write('angle=0' + '\\n')\n",
        "  f.write('saturation = 1.5' + '\\n')\n",
        "  f.write('exposure = 1.5' + '\\n')\n",
        "  f.write('hue = .1' + '\\n')\n",
        "  f.write('\\n')\n",
        "  f.write('learning_rate=0.001' + '\\n')\n",
        "  f.write('burn_in=1000' + '\\n')\n",
        "  ######you can adjust up and down to change training time#####\n",
        "  ##Darknet does iterations with batches, not epochs####\n",
        "  # max_batches = num_classes*2000\n",
        "  max_batches = 2000\n",
        "  f.write('max_batches=' + str(max_batches) + '\\n')\n",
        "  f.write('policy=steps' + '\\n')\n",
        "  steps1 = .8 * max_batches\n",
        "  steps2 = .9 * max_batches\n",
        "  f.write('steps='+str(steps1)+','+str(steps2) + '\\n')\n",
        "\n",
        "# Instructions from the darknet repo\n",
        "# change line classes=80 to your number of objects in each of 3 [yolo]-layers:\n",
        "# change [filters=255] to filters=(classes + 5)x3 in the 3 [convolutional] before each [yolo] layer, \n",
        "# keep in mind that it only has to be the last [convolutional] before each of the [yolo] layers.\n",
        "\n",
        "  with open('cfg/yolov4-custom2.cfg', 'r') as f2:\n",
        "    content = f2.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)    \n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 0,1,2' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "\n",
        "  with open('cfg/yolov4-custom3.cfg', 'r') as f3:\n",
        "    content = f3.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)    \n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 3,4,5' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "\n",
        "  with open('cfg/yolov4-custom4.cfg', 'r') as f4:\n",
        "    content = f4.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)    \n",
        "    num_filters = (num_classes + 5) * 3\n",
        "    f.write('filters='+str(num_filters) + '\\n')\n",
        "    f.write('activation=linear')\n",
        "    f.write('\\n')\n",
        "    f.write('\\n')\n",
        "    f.write('[yolo]' + '\\n')\n",
        "    f.write('mask = 6,7,8' + '\\n')\n",
        "    f.write('anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401' + '\\n')\n",
        "    f.write('classes=' + str(num_classes) + '\\n')\n",
        "    \n",
        "  with open('cfg/yolov4-custom5.cfg', 'r') as f5:\n",
        "    content = f5.readlines()\n",
        "    for line in content:\n",
        "      f.write(line)\n",
        "\n",
        "print(\"file is written!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2LAciMh4Cut"
      },
      "source": [
        "#here is the file that was just written. \n",
        "#you may consider adjusting certain things\n",
        "\n",
        "#like the number of subdivisions 64 runs faster but Colab GPU may not be big enough\n",
        "#if Colab GPU memory is too small, you will need to adjust subdivisions to 16\n",
        "%cat cfg/custom-yolov4-detector.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWrG9EGamSpH"
      },
      "source": [
        "# Train Custom YOLOv4 Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6miYFbvExqMd"
      },
      "source": [
        "!./darknet detector train data/obj.data cfg/custom-yolov4-detector.cfg yolov4.conv.137 -dont_show -map\n",
        "#If you get CUDA out of memory adjust subdivisions above!\n",
        "#adjust max batches down for shorter training above"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBnwpBV5ZXxQ"
      },
      "source": [
        "# Infer Custom Objects with Saved YOLOv4 Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzoJQQw8Zdco"
      },
      "source": [
        "#define utility function\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3dJB6NZv4kh"
      },
      "source": [
        "#check if weigths have saved yet\n",
        "#backup houses the last weights for our detector\n",
        "#(file yolo-obj_last.weights will be saved to the build\\darknet\\x64\\backup\\ for each 100 iterations)\n",
        "#(file yolo-obj_xxxx.weights will be saved to the build\\darknet\\x64\\backup\\ for each 1000 iterations)\n",
        "#After training is complete - get result yolo-obj_final.weights from path build\\darknet\\x64\\bac\n",
        "!ls backup\n",
        "#if it is empty you haven't trained for long enough yet, you need to train for at least 100 iterations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-_E3O5Mf4Mf"
      },
      "source": [
        "#coco.names is hardcoded somewhere in the detector\n",
        "%cp data/obj.names data/coco.names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjKzw2TvZrOQ"
      },
      "source": [
        "\n",
        "#/test has images that we can test our detector on\n",
        "test_images = [f for f in os.listdir('test') if f.endswith('.jpg')]\n",
        "import random\n",
        "img_path = \"test/\" + random.choice(test_images);\n",
        "\n",
        "#test out our detector!\n",
        "!./darknet detect cfg/custom-yolov4-detector.cfg backup/custom-yolov4-detector_final.weights {img_path} -dont-show\n",
        "imShow('/content/darknet/predictions.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}